{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniketsharma00411/CMPUT655-Project/blob/main/rl_project_experiment_structure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-L_EHpYmbjm0"
      },
      "outputs": [],
      "source": [
        "import ray\n",
        "from ray import tune\n",
        "from ray.rllib.agents.ppo import PPOTrainer\n",
        "from ray.rllib.agents.ppo import PPOConfig\n",
        "from popgym.envs import labyrinth_escape, labyrinth_explore\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "import pprint\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha9u5_ue1ERw"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jG_E7dZo1DZd"
      },
      "outputs": [],
      "source": [
        "num_of_cycles = 2 #@param\n",
        "total_timesteps_per_cycle = 12000 #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "X4Xxx6ab1c9j",
        "outputId": "fc69ab2d-4409-4e44-e56e-b9cd65c2fa4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:21:48,526\tINFO worker.py:1553 -- Started a local Ray instance.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
              "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
              "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
              "            <g id=\"layer-1\">\n",
              "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
              "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
              "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
              "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
              "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
              "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
              "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
              "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
              "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
              "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
              "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
              "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
              "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
              "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
              "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
              "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
              "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
              "            </g>\n",
              "        </svg>\n",
              "        <table>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
              "                <td style=\"text-align: left\"><b>3.9.18</b></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
              "                <td style=\"text-align: left\"><b> 2.3.0</b></td>\n",
              "            </tr>\n",
              "            \n",
              "        </table>\n",
              "    </div>\n",
              "</div>\n"
            ],
            "text/plain": [
              "RayContext(dashboard_url='', python_version='3.9.18', ray_version='2.3.0', ray_commit='cf7a56b4b0b648c324722df7c99c168e92ff0b45', address_info={'node_ip_address': '129.128.243.187', 'raylet_ip_address': '129.128.243.187', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-11-28_02-21-46_869339_699633/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-11-28_02-21-46_869339_699633/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-11-28_02-21-46_869339_699633', 'metrics_export_port': 58656, 'gcs_address': '129.128.243.187:42604', 'address': '129.128.243.187:42604', 'dashboard_agent_listen_port': 52365, 'node_id': 'b910e511f76deff8238f2173bc6fc21da57f9fc0dd2862b4450bcf87'})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ray.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-_Hzu6E1sVp"
      },
      "source": [
        "# Defining Environments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YVcv-hbI1nI-"
      },
      "outputs": [],
      "source": [
        "envs = [\"LabyrinthEscapeEasy\", \"LabyrinthEscapeMedium\", \"LabyrinthEscapeHard\", \"LabyrinthExploreEasy\", \"LabyrinthExploreMedium\", \"LabyrinthExploreHard\"]\n",
        "\n",
        "ray.tune.registry.register_env(\"LabyrinthEscapeEasy\", lambda env_config: labyrinth_escape.LabyrinthEscapeEasy())\n",
        "ray.tune.registry.register_env(\"LabyrinthEscapeMedium\", lambda env_config: labyrinth_escape.LabyrinthEscapeMedium())\n",
        "ray.tune.registry.register_env(\"LabyrinthEscapeHard\", lambda env_config: labyrinth_escape.LabyrinthEscapeHard())\n",
        "ray.tune.registry.register_env(\"LabyrinthExploreEasy\", lambda env_config: labyrinth_explore.LabyrinthExploreEasy())\n",
        "ray.tune.registry.register_env(\"LabyrinthExploreMedium\", lambda env_config: labyrinth_explore.LabyrinthExploreMedium())\n",
        "ray.tune.registry.register_env(\"LabyrinthExploreHard\", lambda env_config: labyrinth_explore.LabyrinthExploreHard())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl7bHpo68ME6"
      },
      "source": [
        "# Defining Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9HMPg3fS8OaR"
      },
      "outputs": [],
      "source": [
        "model = {\"use_attention\": True}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph8z44Dm8B1F"
      },
      "source": [
        "# Running Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VXzg1g7d3gIU"
      },
      "outputs": [],
      "source": [
        "mean_reward_per_episode = {}\n",
        "timesteps_done = {}\n",
        "for env in envs:\n",
        "    mean_reward_per_episode[env] = []\n",
        "    timesteps_done[env] = []\n",
        "\n",
        "previous_checkpoint_path = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdjAAgb-oB20",
        "outputId": "879d6aec-08ec-48fc-b139-824590077e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: /home/aniket7/miniconda3/envs/rl_project/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
            "mkdir: cannot create directory ‘saved_weights’: File exists\r\n"
          ]
        }
      ],
      "source": [
        "! mkdir saved_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuMI_iMhKvcr",
        "outputId": "e40dab95-a2e3-426e-e2c0-6dd2666cd02f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbIPRg-72mC7",
        "outputId": "54763d45-7b18-4fc1-da50-3364507eff57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:21:50,432\tWARNING algorithm_config.py:596 -- Cannot create PPOConfig from given `config_dict`! Property num_cpus not supported.\n",
            "2023-11-28 02:21:50,433\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthEscapeEasy', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthEscapeEasy').build()` instead. This will raise an error in the future!\n",
            "2023-11-28 02:21:50,467\tINFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Cycle 0 Environment LabyrinthEscapeEasy:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=707290)\u001b[0m 2023-11-28 02:21:54,128\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=707290)\u001b[0m 2023-11-28 02:21:54,128\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:21:56,161\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 4000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbc35bd6e50>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd5647fd90>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.032520294189453125,\n",
            "                       'StateBufferConnector_ms': 0.005030632019042969,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12227694193522136},\n",
            " 'counters': {'num_agent_steps_sampled': 4000,\n",
            "              'num_agent_steps_trained': 4000,\n",
            "              'num_env_steps_sampled': 4000,\n",
            "              'num_env_steps_trained': 4000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-22-55',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 977.6666666666666,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.1337890625,\n",
            " 'episode_reward_mean': -0.6214192708333334,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 3,\n",
            " 'episodes_total': 3,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 887, 1023],\n",
            "                'episode_reward': [-0.9990234375, 0.1337890625, -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.20000000000000004,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.3345260270180241,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.013330846365923169,\n",
            "                                                           'policy_loss': -0.026522563902601118,\n",
            "                                                           'total_loss': -0.00943128254705219,\n",
            "                                                           'vf_explained_var': -0.9630457308503889,\n",
            "                                                           'vf_loss': 0.014425113884123764},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 4000,\n",
            "          'num_agent_steps_trained': 4000,\n",
            "          'num_env_steps_sampled': 4000,\n",
            "          'num_env_steps_trained': 4000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 4000,\n",
            " 'num_agent_steps_trained': 4000,\n",
            " 'num_env_steps_sampled': 4000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 4000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.4329411764705884,\n",
            "          'ram_util_percent': 5.068235294117649},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.0935289515429053,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11581173543629797,\n",
            "                  'mean_inference_ms': 2.6595894344723185,\n",
            "                  'mean_raw_obs_processing_ms': 0.2847383484212077},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.032520294189453125,\n",
            "                                           'StateBufferConnector_ms': 0.005030632019042969,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12227694193522136},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 977.6666666666666,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.1337890625,\n",
            "                     'episode_reward_mean': -0.6214192708333334,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 3,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 887, 1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       0.1337890625,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.0935289515429053,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11581173543629797,\n",
            "                                      'mean_inference_ms': 2.6595894344723185,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2847383484212077}},\n",
            " 'time_since_restore': 59.46778655052185,\n",
            " 'time_this_iter_s': 59.46778655052185,\n",
            " 'time_total_s': 59.46778655052185,\n",
            " 'timers': {'learn_throughput': 75.356,\n",
            "            'learn_time_ms': 53081.681,\n",
            "            'load_throughput': 164724.752,\n",
            "            'load_time_ms': 24.283,\n",
            "            'synch_weights_time_ms': 5.342,\n",
            "            'training_iteration_time_ms': 59460.852},\n",
            " 'timestamp': 1701163375,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 4000,\n",
            " 'training_iteration': 1,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 5.699561595916748}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 8000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbc35bd6e50>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd56483400>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03298521041870117,\n",
            "                       'StateBufferConnector_ms': 0.004929304122924805,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.1233220100402832},\n",
            " 'counters': {'num_agent_steps_sampled': 8000,\n",
            "              'num_agent_steps_trained': 8000,\n",
            "              'num_env_steps_sampled': 8000,\n",
            "              'num_env_steps_trained': 8000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-23-56',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 902.5,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.6064453125,\n",
            " 'episode_reward_mean': -0.50634765625,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 5,\n",
            " 'episodes_total': 8,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    887,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    815,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    403],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   0.1337890625,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   0.2041015625,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   0.6064453125]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.20000000000000004,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.308665511172305,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01785975133123781,\n",
            "                                                           'policy_loss': -0.017312351918669158,\n",
            "                                                           'total_loss': 0.007148607279504499,\n",
            "                                                           'vf_explained_var': -0.939364884168871,\n",
            "                                                           'vf_loss': 0.02088900934404103},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1395.5}},\n",
            "          'num_agent_steps_sampled': 8000,\n",
            "          'num_agent_steps_trained': 8000,\n",
            "          'num_env_steps_sampled': 8000,\n",
            "          'num_env_steps_trained': 8000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 8000,\n",
            " 'num_agent_steps_trained': 8000,\n",
            " 'num_env_steps_sampled': 8000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 8000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.2551724137931033,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09319778483137198,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11555062618475828,\n",
            "                  'mean_inference_ms': 2.662063848821781,\n",
            "                  'mean_raw_obs_processing_ms': 0.28587418657887487},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03298521041870117,\n",
            "                                           'StateBufferConnector_ms': 0.004929304122924805,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.1233220100402832},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 902.5,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.6064453125,\n",
            "                     'episode_reward_mean': -0.50634765625,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 5,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        887,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        815,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        403],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       0.1337890625,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       0.2041015625,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       0.6064453125]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09319778483137198,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11555062618475828,\n",
            "                                      'mean_inference_ms': 2.662063848821781,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28587418657887487}},\n",
            " 'time_since_restore': 120.43803644180298,\n",
            " 'time_this_iter_s': 60.97024989128113,\n",
            " 'time_total_s': 120.43803644180298,\n",
            " 'timers': {'learn_throughput': 74.312,\n",
            "            'learn_time_ms': 53826.892,\n",
            "            'load_throughput': 195003.411,\n",
            "            'load_time_ms': 20.512,\n",
            "            'synch_weights_time_ms': 5.397,\n",
            "            'training_iteration_time_ms': 60212.121},\n",
            " 'timestamp': 1701163436,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 8000,\n",
            " 'training_iteration': 2,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 5.699561595916748}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:24:58,257\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthEscapeMedium', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthEscapeMedium').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 12000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbc35bd6e50>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd564842e0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03290543189415565,\n",
            "                       'StateBufferConnector_ms': 0.004931596609262319,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12337978069598858},\n",
            " 'counters': {'num_agent_steps_sampled': 12000,\n",
            "              'num_agent_steps_trained': 12000,\n",
            "              'num_env_steps_sampled': 12000,\n",
            "              'num_env_steps_trained': 12000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-24-58',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 860.8461538461538,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.8193359375,\n",
            " 'episode_reward_mean': -0.4560546875,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 5,\n",
            " 'episodes_total': 13,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    887,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    815,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    403,\n",
            "                                    1023,\n",
            "                                    185,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    717],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   0.1337890625,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   0.2041015625,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   0.6064453125,\n",
            "                                   -0.9990234375,\n",
            "                                   0.8193359375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   0.2998046875]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.20000000000000004,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.2950234978429733,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01466296703374121,\n",
            "                                                           'policy_loss': -0.016737752720232934,\n",
            "                                                           'total_loss': 0.0069107667813378,\n",
            "                                                           'vf_explained_var': -0.9553555596259332,\n",
            "                                                           'vf_loss': 0.02071592479284542},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2325.5}},\n",
            "          'num_agent_steps_sampled': 12000,\n",
            "          'num_agent_steps_trained': 12000,\n",
            "          'num_env_steps_sampled': 12000,\n",
            "          'num_env_steps_trained': 12000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 12000,\n",
            " 'num_agent_steps_trained': 12000,\n",
            " 'num_env_steps_sampled': 12000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 12000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.2818181818181817,\n",
            "          'ram_util_percent': 5.1000000000000005},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.0931376957870545,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11541780980096432,\n",
            "                  'mean_inference_ms': 2.664176554701714,\n",
            "                  'mean_raw_obs_processing_ms': 0.2864792454458657},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03290543189415565,\n",
            "                                           'StateBufferConnector_ms': 0.004931596609262319,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12337978069598858},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 860.8461538461538,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.8193359375,\n",
            "                     'episode_reward_mean': -0.4560546875,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 5,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        887,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        815,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        403,\n",
            "                                                        1023,\n",
            "                                                        185,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        717],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       0.1337890625,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       0.2041015625,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       0.6064453125,\n",
            "                                                       -0.9990234375,\n",
            "                                                       0.8193359375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       0.2998046875]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.0931376957870545,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11541780980096432,\n",
            "                                      'mean_inference_ms': 2.664176554701714,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2864792454458657}},\n",
            " 'time_since_restore': 181.94058060646057,\n",
            " 'time_this_iter_s': 61.50254416465759,\n",
            " 'time_total_s': 181.94058060646057,\n",
            " 'timers': {'learn_throughput': 73.743,\n",
            "            'learn_time_ms': 54242.111,\n",
            "            'load_throughput': 206767.047,\n",
            "            'load_time_ms': 19.345,\n",
            "            'synch_weights_time_ms': 5.729,\n",
            "            'training_iteration_time_ms': 60640.383},\n",
            " 'timestamp': 1701163498,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 12000,\n",
            " 'training_iteration': 3,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 5.699561595916748}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 0 Environment LabyrinthEscapeMedium:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=719077)\u001b[0m 2023-11-28 02:25:01,926\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=719077)\u001b[0m 2023-11-28 02:25:01,926\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:25:02,808\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:25:02,840\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_0_env_LabyrinthEscapeEasy/checkpoint_000003\n",
            "2023-11-28 02:25:02,840\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 181.94058060646057, '_episodes_total': 13}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 16000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbc35bd6dc0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbc35bceb50>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030851364135742188,\n",
            "                       'StateBufferConnector_ms': 0.0049114227294921875,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12346506118774414},\n",
            " 'counters': {'num_agent_steps_sampled': 16000,\n",
            "              'num_agent_steps_trained': 16000,\n",
            "              'num_env_steps_sampled': 16000,\n",
            "              'num_env_steps_trained': 16000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-26-13',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.9990234375,\n",
            " 'episode_reward_mean': -0.9990234375,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 2,\n",
            " 'episodes_total': 15,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                'episode_reward': [-0.9990234375, -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.20000000000000004,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.2956378876522023,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.017200450977293013,\n",
            "                                                           'policy_loss': 0.007175509691719086,\n",
            "                                                           'total_loss': 0.013121036107661903,\n",
            "                                                           'vf_explained_var': -0.9855440412477781,\n",
            "                                                           'vf_loss': 0.002505439491372966},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 16000,\n",
            "          'num_agent_steps_trained': 16000,\n",
            "          'num_env_steps_sampled': 16000,\n",
            "          'num_env_steps_trained': 16000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 16000,\n",
            " 'num_agent_steps_trained': 16000,\n",
            " 'num_env_steps_sampled': 16000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 16000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.0306930693069307,\n",
            "          'ram_util_percent': 5.105940594059407},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.0949317011339911,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11723325110744798,\n",
            "                  'mean_inference_ms': 2.643042239828267,\n",
            "                  'mean_raw_obs_processing_ms': 0.284679409029006},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030851364135742188,\n",
            "                                           'StateBufferConnector_ms': 0.0049114227294921875,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12346506118774414},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.9990234375,\n",
            "                     'episode_reward_mean': -0.9990234375,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 2,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.0949317011339911,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11723325110744798,\n",
            "                                      'mean_inference_ms': 2.643042239828267,\n",
            "                                      'mean_raw_obs_processing_ms': 0.284679409029006}},\n",
            " 'time_since_restore': 70.31877541542053,\n",
            " 'time_this_iter_s': 70.31877541542053,\n",
            " 'time_total_s': 252.2593560218811,\n",
            " 'timers': {'learn_throughput': 62.604,\n",
            "            'learn_time_ms': 63894.165,\n",
            "            'load_throughput': 68239.178,\n",
            "            'load_time_ms': 58.617,\n",
            "            'synch_weights_time_ms': 7.14,\n",
            "            'training_iteration_time_ms': 70310.555},\n",
            " 'timestamp': 1701163573,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 16000,\n",
            " 'training_iteration': 4,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.576380252838135}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 20000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbc35bd6dc0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c20f940>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.032166639963785805,\n",
            "                       'StateBufferConnector_ms': 0.0049432118733723955,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12307167053222656},\n",
            " 'counters': {'num_agent_steps_sampled': 20000,\n",
            "              'num_agent_steps_trained': 20000,\n",
            "              'num_env_steps_sampled': 20000,\n",
            "              'num_env_steps_trained': 20000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-27-24',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.9990234375,\n",
            " 'episode_reward_mean': -0.9990234375,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 19,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.2,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.2829984923203785,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.015377064852727926,\n",
            "                                                           'policy_loss': -0.019422785685294205,\n",
            "                                                           'total_loss': -0.014752403245204024,\n",
            "                                                           'vf_explained_var': -0.9581598845289813,\n",
            "                                                           'vf_loss': 0.0015949704767424717},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 20000,\n",
            "          'num_agent_steps_trained': 20000,\n",
            "          'num_env_steps_sampled': 20000,\n",
            "          'num_env_steps_trained': 20000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 20000,\n",
            " 'num_agent_steps_trained': 20000,\n",
            " 'num_env_steps_sampled': 20000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 20000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 2.9722772277227727,\n",
            "          'ram_util_percent': 5.100000000000001},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.0947750664008834,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11664812793289032,\n",
            "                  'mean_inference_ms': 2.6397665803984727,\n",
            "                  'mean_raw_obs_processing_ms': 0.2860617335318803},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.032166639963785805,\n",
            "                                           'StateBufferConnector_ms': 0.0049432118733723955,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12307167053222656},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.9990234375,\n",
            "                     'episode_reward_mean': -0.9990234375,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.0947750664008834,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11664812793289032,\n",
            "                                      'mean_inference_ms': 2.6397665803984727,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2860617335318803}},\n",
            " 'time_since_restore': 141.4348967075348,\n",
            " 'time_this_iter_s': 71.11612129211426,\n",
            " 'time_total_s': 323.37547731399536,\n",
            " 'timers': {'learn_throughput': 62.173,\n",
            "            'learn_time_ms': 64336.54,\n",
            "            'load_throughput': 105171.801,\n",
            "            'load_time_ms': 38.033,\n",
            "            'synch_weights_time_ms': 6.374,\n",
            "            'training_iteration_time_ms': 70710.513},\n",
            " 'timestamp': 1701163644,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 20000,\n",
            " 'training_iteration': 5,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.576380252838135}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:28:32,779\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthEscapeHard', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthEscapeHard').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 24000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbc35bd6dc0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd56425610>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03299279646439986,\n",
            "                       'StateBufferConnector_ms': 0.0049591064453125,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12296763333407315},\n",
            " 'counters': {'num_agent_steps_sampled': 24000,\n",
            "              'num_agent_steps_trained': 24000,\n",
            "              'num_env_steps_sampled': 24000,\n",
            "              'num_env_steps_trained': 24000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-28-32',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 985.9090909090909,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.3994140625,\n",
            " 'episode_reward_mean': -0.8718927556818182,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 5,\n",
            " 'episodes_total': 24,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    615,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   0.3994140625,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.20000000000000004,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.248193545110764,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01796652211158152,\n",
            "                                                           'policy_loss': -0.04056200914645708,\n",
            "                                                           'total_loss': -0.022660470293253982,\n",
            "                                                           'vf_explained_var': -0.9697498515088071,\n",
            "                                                           'vf_loss': 0.014308232964474648},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2295.5}},\n",
            "          'num_agent_steps_sampled': 24000,\n",
            "          'num_agent_steps_trained': 24000,\n",
            "          'num_env_steps_sampled': 24000,\n",
            "          'num_env_steps_trained': 24000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 24000,\n",
            " 'num_agent_steps_trained': 24000,\n",
            " 'num_env_steps_sampled': 24000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 24000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.239795918367347,\n",
            "          'ram_util_percent': 5.100000000000001},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09459318774395027,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11638653757163321,\n",
            "                  'mean_inference_ms': 2.6386717253612972,\n",
            "                  'mean_raw_obs_processing_ms': 0.2868080061666385},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03299279646439986,\n",
            "                                           'StateBufferConnector_ms': 0.0049591064453125,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12296763333407315},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 985.9090909090909,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.3994140625,\n",
            "                     'episode_reward_mean': -0.8718927556818182,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 5,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        615,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       0.3994140625,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09459318774395027,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11638653757163321,\n",
            "                                      'mean_inference_ms': 2.6386717253612972,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2868080061666385}},\n",
            " 'time_since_restore': 209.81451296806335,\n",
            " 'time_this_iter_s': 68.37961626052856,\n",
            " 'time_total_s': 391.7550935745239,\n",
            " 'timers': {'learn_throughput': 62.938,\n",
            "            'learn_time_ms': 63554.935,\n",
            "            'load_throughput': 113154.411,\n",
            "            'load_time_ms': 35.35,\n",
            "            'synch_weights_time_ms': 6.287,\n",
            "            'training_iteration_time_ms': 69931.339},\n",
            " 'timestamp': 1701163712,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 24000,\n",
            " 'training_iteration': 6,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.576380252838135}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 0 Environment LabyrinthEscapeHard:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=730618)\u001b[0m 2023-11-28 02:28:36,487\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=730618)\u001b[0m 2023-11-28 02:28:36,487\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:28:37,391\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:28:37,425\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_0_env_LabyrinthEscapeMedium/checkpoint_000006\n",
            "2023-11-28 02:28:37,425\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 6, '_timesteps_total': None, '_time_total': 391.7550935745239, '_episodes_total': 24}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 28000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd56243af0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd56485ee0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030040740966796875,\n",
            "                       'StateBufferConnector_ms': 0.004998842875162761,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12343724568684895},\n",
            " 'counters': {'num_agent_steps_sampled': 28000,\n",
            "              'num_agent_steps_trained': 28000,\n",
            "              'num_env_steps_sampled': 28000,\n",
            "              'num_env_steps_trained': 28000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-29-44',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 927.3333333333334,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.28125,\n",
            " 'episode_reward_mean': -0.572265625,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 3,\n",
            " 'episodes_total': 27,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 736, 1023],\n",
            "                'episode_reward': [-0.9990234375, 0.28125, -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.20000000000000004,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.2291775311193158,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.014093054792301114,\n",
            "                                                           'policy_loss': -0.011645051548557897,\n",
            "                                                           'total_loss': 0.0028181353003107093,\n",
            "                                                           'vf_explained_var': -0.9935751658613964,\n",
            "                                                           'vf_loss': 0.011644578258311677},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 28000,\n",
            "          'num_agent_steps_trained': 28000,\n",
            "          'num_env_steps_sampled': 28000,\n",
            "          'num_env_steps_trained': 28000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 28000,\n",
            " 'num_agent_steps_trained': 28000,\n",
            " 'num_env_steps_sampled': 28000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 28000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.155208333333333, 'ram_util_percent': 5.10625},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09437181662464666,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11779005758249618,\n",
            "                  'mean_inference_ms': 2.6156461459288054,\n",
            "                  'mean_raw_obs_processing_ms': 0.28697125379113425},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030040740966796875,\n",
            "                                           'StateBufferConnector_ms': 0.004998842875162761,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12343724568684895},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 927.3333333333334,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.28125,\n",
            "                     'episode_reward_mean': -0.572265625,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 3,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 736, 1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       0.28125,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09437181662464666,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11779005758249618,\n",
            "                                      'mean_inference_ms': 2.6156461459288054,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28697125379113425}},\n",
            " 'time_since_restore': 66.76794242858887,\n",
            " 'time_this_iter_s': 66.76794242858887,\n",
            " 'time_total_s': 458.5230360031128,\n",
            " 'timers': {'learn_throughput': 66.231,\n",
            "            'learn_time_ms': 60394.812,\n",
            "            'load_throughput': 71325.939,\n",
            "            'load_time_ms': 56.081,\n",
            "            'synch_weights_time_ms': 5.441,\n",
            "            'training_iteration_time_ms': 66761.788},\n",
            " 'timestamp': 1701163784,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 28000,\n",
            " 'training_iteration': 7,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.640798807144165}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 32000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd56243af0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd5647b850>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03294944763183594,\n",
            "                       'StateBufferConnector_ms': 0.004945482526506696,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.1234020505632673},\n",
            " 'counters': {'num_agent_steps_sampled': 32000,\n",
            "              'num_agent_steps_trained': 32000,\n",
            "              'num_env_steps_sampled': 32000,\n",
            "              'num_env_steps_trained': 32000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-30-48',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 982.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.28125,\n",
            " 'episode_reward_mean': -0.8161272321428571,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 31,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 736, 1023, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   0.28125,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.2,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.191654008494483,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.02176798983197336,\n",
            "                                                           'policy_loss': -0.017230306658893822,\n",
            "                                                           'total_loss': -0.011274625627944866,\n",
            "                                                           'vf_explained_var': -0.9624235412147311,\n",
            "                                                           'vf_loss': 0.0016020839154953137},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 32000,\n",
            "          'num_agent_steps_trained': 32000,\n",
            "          'num_env_steps_sampled': 32000,\n",
            "          'num_env_steps_trained': 32000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 32000,\n",
            " 'num_agent_steps_trained': 32000,\n",
            " 'num_env_steps_sampled': 32000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 32000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.1499999999999995,\n",
            "          'ram_util_percent': 5.100000000000001},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09401783050978255,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11703829764188438,\n",
            "                  'mean_inference_ms': 2.6152665529419195,\n",
            "                  'mean_raw_obs_processing_ms': 0.2878496967215752},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03294944763183594,\n",
            "                                           'StateBufferConnector_ms': 0.004945482526506696,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.1234020505632673},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 982.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.28125,\n",
            "                     'episode_reward_mean': -0.8161272321428571,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        736,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       0.28125,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09401783050978255,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11703829764188438,\n",
            "                                      'mean_inference_ms': 2.6152665529419195,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2878496967215752}},\n",
            " 'time_since_restore': 131.12441086769104,\n",
            " 'time_this_iter_s': 64.35646843910217,\n",
            " 'time_total_s': 522.879504442215,\n",
            " 'timers': {'learn_throughput': 67.584,\n",
            "            'learn_time_ms': 59185.636,\n",
            "            'load_throughput': 69723.205,\n",
            "            'load_time_ms': 57.37,\n",
            "            'synch_weights_time_ms': 5.677,\n",
            "            'training_iteration_time_ms': 65555.956},\n",
            " 'timestamp': 1701163848,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 32000,\n",
            " 'training_iteration': 8,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.640798807144165}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:31:53,717\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthExploreEasy', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthExploreEasy').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 36000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd56243af0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd564669d0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03275871276855469,\n",
            "                       'StateBufferConnector_ms': 0.004941766912286932,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12301965193314986},\n",
            " 'counters': {'num_agent_steps_sampled': 36000,\n",
            "              'num_agent_steps_trained': 36000,\n",
            "              'num_env_steps_sampled': 36000,\n",
            "              'num_env_steps_trained': 36000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-31-53',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 996.9090909090909,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.28125,\n",
            " 'episode_reward_mean': -0.8826349431818182,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 35,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    736,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   0.28125,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.3,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.190823244792159,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.017957349827307182,\n",
            "                                                           'policy_loss': -0.041717841125704265,\n",
            "                                                           'total_loss': -0.034659582640855544,\n",
            "                                                           'vf_explained_var': -0.981815387677121,\n",
            "                                                           'vf_loss': 0.0016710524350562464},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2295.5}},\n",
            "          'num_agent_steps_sampled': 36000,\n",
            "          'num_agent_steps_trained': 36000,\n",
            "          'num_env_steps_sampled': 36000,\n",
            "          'num_env_steps_trained': 36000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 36000,\n",
            " 'num_agent_steps_trained': 36000,\n",
            " 'num_env_steps_sampled': 36000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 36000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.226086956521739,\n",
            "          'ram_util_percent': 5.100000000000001},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09385959008115675,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11663075513599828,\n",
            "                  'mean_inference_ms': 2.614488310904667,\n",
            "                  'mean_raw_obs_processing_ms': 0.2882943291098598},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03275871276855469,\n",
            "                                           'StateBufferConnector_ms': 0.004941766912286932,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12301965193314986},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 996.9090909090909,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.28125,\n",
            "                     'episode_reward_mean': -0.8826349431818182,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        736,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       0.28125,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09385959008115675,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11663075513599828,\n",
            "                                      'mean_inference_ms': 2.614488310904667,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2882943291098598}},\n",
            " 'time_since_restore': 196.16387343406677,\n",
            " 'time_this_iter_s': 65.03946256637573,\n",
            " 'time_total_s': 587.9189670085907,\n",
            " 'timers': {'learn_throughput': 67.764,\n",
            "            'learn_time_ms': 59028.279,\n",
            "            'load_throughput': 68754.949,\n",
            "            'load_time_ms': 58.178,\n",
            "            'synch_weights_time_ms': 5.114,\n",
            "            'training_iteration_time_ms': 65381.954},\n",
            " 'timestamp': 1701163913,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 36000,\n",
            " 'training_iteration': 9,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.640798807144165}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 0 Environment LabyrinthExploreEasy:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=743045)\u001b[0m 2023-11-28 02:31:57,431\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=743045)\u001b[0m 2023-11-28 02:31:57,431\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:31:58,339\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:31:58,369\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_0_env_LabyrinthEscapeHard/checkpoint_000009\n",
            "2023-11-28 02:31:58,369\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 9, '_timesteps_total': None, '_time_total': 587.9189670085907, '_episodes_total': 35}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 40000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd5661b550>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c25d910>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.029206275939941406,\n",
            "                       'StateBufferConnector_ms': 0.0051021575927734375,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12110471725463867},\n",
            " 'counters': {'num_agent_steps_sampled': 40000,\n",
            "              'num_agent_steps_trained': 40000,\n",
            "              'num_env_steps_sampled': 40000,\n",
            "              'num_env_steps_trained': 40000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-33-03',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.4216358418367345,\n",
            " 'episode_reward_mean': -0.6034060108418366,\n",
            " 'episode_reward_min': -0.7851761798469388,\n",
            " 'episodes_this_iter': 2,\n",
            " 'episodes_total': 37,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                'episode_reward': [-0.4216358418367345, -0.7851761798469388]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.3,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.1951671550350804,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.015104580560720386,\n",
            "                                                           'policy_loss': -0.05711055866252351,\n",
            "                                                           'total_loss': -0.049121696814413994,\n",
            "                                                           'vf_explained_var': -0.9579104800057667,\n",
            "                                                           'vf_loss': 0.003457488430356006},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 40000,\n",
            "          'num_agent_steps_trained': 40000,\n",
            "          'num_env_steps_sampled': 40000,\n",
            "          'num_env_steps_trained': 40000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 40000,\n",
            " 'num_agent_steps_trained': 40000,\n",
            " 'num_env_steps_sampled': 40000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 40000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.2537634408602147,\n",
            "          'ram_util_percent': 5.106451612903228},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09486688368919788,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.13799967615679465,\n",
            "                  'mean_inference_ms': 2.6447621063850093,\n",
            "                  'mean_raw_obs_processing_ms': 0.2833110341306092},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.029206275939941406,\n",
            "                                           'StateBufferConnector_ms': 0.0051021575927734375,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12110471725463867},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.4216358418367345,\n",
            "                     'episode_reward_mean': -0.6034060108418366,\n",
            "                     'episode_reward_min': -0.7851761798469388,\n",
            "                     'episodes_this_iter': 2,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                                    'episode_reward': [-0.4216358418367345,\n",
            "                                                       -0.7851761798469388]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09486688368919788,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.13799967615679465,\n",
            "                                      'mean_inference_ms': 2.6447621063850093,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2833110341306092}},\n",
            " 'time_since_restore': 64.64149761199951,\n",
            " 'time_this_iter_s': 64.64149761199951,\n",
            " 'time_total_s': 652.5604646205902,\n",
            " 'timers': {'learn_throughput': 68.737,\n",
            "            'learn_time_ms': 58193.06,\n",
            "            'load_throughput': 89487.553,\n",
            "            'load_time_ms': 44.699,\n",
            "            'synch_weights_time_ms': 4.983,\n",
            "            'training_iteration_time_ms': 64632.874},\n",
            " 'timestamp': 1701163983,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 40000,\n",
            " 'training_iteration': 10,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.647765636444092}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 44000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd5661b550>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd56489430>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03103812535603841,\n",
            "                       'StateBufferConnector_ms': 0.005054473876953125,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12102921803792317},\n",
            " 'counters': {'num_agent_steps_sampled': 44000,\n",
            "              'num_agent_steps_trained': 44000,\n",
            "              'num_env_steps_sampled': 44000,\n",
            "              'num_env_steps_trained': 44000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-34-07',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.29332748724489777,\n",
            " 'episode_reward_mean': -0.4679694143282312,\n",
            " 'episode_reward_min': -0.7851761798469388,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 41,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.4216358418367345,\n",
            "                                   -0.7851761798469388,\n",
            "                                   -0.35748166454081587,\n",
            "                                   -0.42163584183673475,\n",
            "                                   -0.5285594706632654,\n",
            "                                   -0.29332748724489777]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.29999999999999993,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.1587624861796697,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.014295805839129672,\n",
            "                                                           'policy_loss': -0.019129505943920877,\n",
            "                                                           'total_loss': -0.011837080799871022,\n",
            "                                                           'vf_explained_var': -0.9394649892383151,\n",
            "                                                           'vf_loss': 0.0030036818018803996},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 44000,\n",
            "          'num_agent_steps_trained': 44000,\n",
            "          'num_env_steps_sampled': 44000,\n",
            "          'num_env_steps_trained': 44000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 44000,\n",
            " 'num_agent_steps_trained': 44000,\n",
            " 'num_env_steps_sampled': 44000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 44000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.1402173913043483,\n",
            "          'ram_util_percent': 5.100000000000001},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09477608482669186,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.1376172018501308,\n",
            "                  'mean_inference_ms': 2.6473999036093994,\n",
            "                  'mean_raw_obs_processing_ms': 0.2842253511113941},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03103812535603841,\n",
            "                                           'StateBufferConnector_ms': 0.005054473876953125,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12102921803792317},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.29332748724489777,\n",
            "                     'episode_reward_mean': -0.4679694143282312,\n",
            "                     'episode_reward_min': -0.7851761798469388,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.4216358418367345,\n",
            "                                                       -0.7851761798469388,\n",
            "                                                       -0.35748166454081587,\n",
            "                                                       -0.42163584183673475,\n",
            "                                                       -0.5285594706632654,\n",
            "                                                       -0.29332748724489777]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09477608482669186,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.1376172018501308,\n",
            "                                      'mean_inference_ms': 2.6473999036093994,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2842253511113941}},\n",
            " 'time_since_restore': 129.23720288276672,\n",
            " 'time_this_iter_s': 64.59570527076721,\n",
            " 'time_total_s': 717.1561698913574,\n",
            " 'timers': {'learn_throughput': 68.777,\n",
            "            'learn_time_ms': 58158.888,\n",
            "            'load_throughput': 80807.126,\n",
            "            'load_time_ms': 49.501,\n",
            "            'synch_weights_time_ms': 5.107,\n",
            "            'training_iteration_time_ms': 64610.802},\n",
            " 'timestamp': 1701164047,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 44000,\n",
            " 'training_iteration': 11,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.647765636444092}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:35:14,927\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthExploreMedium', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthExploreMedium').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 48000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd5661b550>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c883070>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03130912780761719,\n",
            "                       'StateBufferConnector_ms': 0.005042552947998047,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.1207876205444336},\n",
            " 'counters': {'num_agent_steps_sampled': 48000,\n",
            "              'num_agent_steps_trained': 48000,\n",
            "              'num_env_steps_sampled': 48000,\n",
            "              'num_env_steps_trained': 48000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-35-14',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.29332748724489777,\n",
            " 'episode_reward_mean': -0.4750976562499999,\n",
            " 'episode_reward_min': -0.7851761798469388,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 45,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.4216358418367345,\n",
            "                                   -0.7851761798469388,\n",
            "                                   -0.35748166454081587,\n",
            "                                   -0.42163584183673475,\n",
            "                                   -0.5285594706632654,\n",
            "                                   -0.29332748724489777,\n",
            "                                   -0.46440529336734704,\n",
            "                                   -0.3147122130102038,\n",
            "                                   -0.656867825255102,\n",
            "                                   -0.5071747448979592]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.3,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.1425841266109098,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.016987995547899645,\n",
            "                                                           'policy_loss': -0.028506949860402333,\n",
            "                                                           'total_loss': -0.018764012723520237,\n",
            "                                                           'vf_explained_var': -0.9453539157746941,\n",
            "                                                           'vf_loss': 0.0046465374780343145},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2295.5}},\n",
            "          'num_agent_steps_sampled': 48000,\n",
            "          'num_agent_steps_trained': 48000,\n",
            "          'num_env_steps_sampled': 48000,\n",
            "          'num_env_steps_trained': 48000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 48000,\n",
            " 'num_agent_steps_trained': 48000,\n",
            " 'num_env_steps_sampled': 48000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 48000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.1166666666666667,\n",
            "          'ram_util_percent': 5.1000000000000005},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09471011284655023,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.1374185450297491,\n",
            "                  'mean_inference_ms': 2.647344591264142,\n",
            "                  'mean_raw_obs_processing_ms': 0.2844928949782607},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03130912780761719,\n",
            "                                           'StateBufferConnector_ms': 0.005042552947998047,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.1207876205444336},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.29332748724489777,\n",
            "                     'episode_reward_mean': -0.4750976562499999,\n",
            "                     'episode_reward_min': -0.7851761798469388,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.4216358418367345,\n",
            "                                                       -0.7851761798469388,\n",
            "                                                       -0.35748166454081587,\n",
            "                                                       -0.42163584183673475,\n",
            "                                                       -0.5285594706632654,\n",
            "                                                       -0.29332748724489777,\n",
            "                                                       -0.46440529336734704,\n",
            "                                                       -0.3147122130102038,\n",
            "                                                       -0.656867825255102,\n",
            "                                                       -0.5071747448979592]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09471011284655023,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.1374185450297491,\n",
            "                                      'mean_inference_ms': 2.647344591264142,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2844928949782607}},\n",
            " 'time_since_restore': 196.44751572608948,\n",
            " 'time_this_iter_s': 67.21031284332275,\n",
            " 'time_total_s': 784.3664827346802,\n",
            " 'timers': {'learn_throughput': 67.768,\n",
            "            'learn_time_ms': 59024.476,\n",
            "            'load_throughput': 77654.92,\n",
            "            'load_time_ms': 51.51,\n",
            "            'synch_weights_time_ms': 5.114,\n",
            "            'training_iteration_time_ms': 65474.51},\n",
            " 'timestamp': 1701164114,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 48000,\n",
            " 'training_iteration': 12,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.647765636444092}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 0 Environment LabyrinthExploreMedium:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=754511)\u001b[0m 2023-11-28 02:35:18,570\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=754511)\u001b[0m 2023-11-28 02:35:18,570\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:35:19,484\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:35:19,517\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_0_env_LabyrinthExploreEasy/checkpoint_000012\n",
            "2023-11-28 02:35:19,518\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 12, '_timesteps_total': None, '_time_total': 784.3664827346802, '_episodes_total': 45}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 52000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd15741670>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd156d4850>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030863285064697266,\n",
            "                       'StateBufferConnector_ms': 0.005114078521728516,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12060403823852539},\n",
            " 'counters': {'num_agent_steps_sampled': 52000,\n",
            "              'num_agent_steps_trained': 52000,\n",
            "              'num_env_steps_sampled': 52000,\n",
            "              'num_env_steps_trained': 52000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-36-26',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.581447326030928,\n",
            " 'episode_reward_mean': -0.6378765302835052,\n",
            " 'episode_reward_min': -0.6943057345360824,\n",
            " 'episodes_this_iter': 2,\n",
            " 'episodes_total': 47,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                'episode_reward': [-0.6943057345360824, -0.581447326030928]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.3,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.150893045497197,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01597529215796385,\n",
            "                                                           'policy_loss': -0.047314095032471484,\n",
            "                                                           'total_loss': -0.04043781648400009,\n",
            "                                                           'vf_explained_var': -0.9845737468811774,\n",
            "                                                           'vf_loss': 0.002083690399153819},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 52000,\n",
            "          'num_agent_steps_trained': 52000,\n",
            "          'num_env_steps_sampled': 52000,\n",
            "          'num_env_steps_trained': 52000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 52000,\n",
            " 'num_agent_steps_trained': 52000,\n",
            " 'num_env_steps_sampled': 52000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 52000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.484536082474227,\n",
            "          'ram_util_percent': 5.10618556701031},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09375789771968873,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.13965210397502054,\n",
            "                  'mean_inference_ms': 2.626361815944902,\n",
            "                  'mean_raw_obs_processing_ms': 0.2816012952996158},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030863285064697266,\n",
            "                                           'StateBufferConnector_ms': 0.005114078521728516,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12060403823852539},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.581447326030928,\n",
            "                     'episode_reward_mean': -0.6378765302835052,\n",
            "                     'episode_reward_min': -0.6943057345360824,\n",
            "                     'episodes_this_iter': 2,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                                    'episode_reward': [-0.6943057345360824,\n",
            "                                                       -0.581447326030928]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09375789771968873,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.13965210397502054,\n",
            "                                      'mean_inference_ms': 2.626361815944902,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2816012952996158}},\n",
            " 'time_since_restore': 67.4146180152893,\n",
            " 'time_this_iter_s': 67.4146180152893,\n",
            " 'time_total_s': 851.7811007499695,\n",
            " 'timers': {'learn_throughput': 65.557,\n",
            "            'learn_time_ms': 61015.421,\n",
            "            'load_throughput': 75754.925,\n",
            "            'load_time_ms': 52.802,\n",
            "            'synch_weights_time_ms': 5.322,\n",
            "            'training_iteration_time_ms': 67409.082},\n",
            " 'timestamp': 1701164186,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 52000,\n",
            " 'training_iteration': 13,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.5855793952941895}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 56000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd15741670>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd56481220>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03130038579305013,\n",
            "                       'StateBufferConnector_ms': 0.0050703684488932295,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12079079945882161},\n",
            " 'counters': {'num_agent_steps_sampled': 56000,\n",
            "              'num_agent_steps_trained': 56000,\n",
            "              'num_env_steps_sampled': 56000,\n",
            "              'num_env_steps_trained': 56000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-37-32',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.5137322809278349,\n",
            " 'episode_reward_mean': -0.6754959997852233,\n",
            " 'episode_reward_min': -0.8071641430412375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 51,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.6943057345360824,\n",
            "                                   -0.581447326030928,\n",
            "                                   -0.7507349387886597,\n",
            "                                   -0.8071641430412375,\n",
            "                                   -0.5137322809278349,\n",
            "                                   -0.7055915753865979]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.29999999999999993,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.1234747699896495,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.018769200225603223,\n",
            "                                                           'policy_loss': -0.02181749043779241,\n",
            "                                                           'total_loss': -0.014216122476177083,\n",
            "                                                           'vf_explained_var': -0.9560286463300387,\n",
            "                                                           'vf_loss': 0.001970607399319609},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 56000,\n",
            "          'num_agent_steps_trained': 56000,\n",
            "          'num_env_steps_sampled': 56000,\n",
            "          'num_env_steps_trained': 56000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 56000,\n",
            " 'num_agent_steps_trained': 56000,\n",
            " 'num_env_steps_sampled': 56000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 56000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.1322580645161286,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.0936312198137282,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.1390783239664656,\n",
            "                  'mean_inference_ms': 2.6300325149781867,\n",
            "                  'mean_raw_obs_processing_ms': 0.2831254668181497},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03130038579305013,\n",
            "                                           'StateBufferConnector_ms': 0.0050703684488932295,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12079079945882161},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.5137322809278349,\n",
            "                     'episode_reward_mean': -0.6754959997852233,\n",
            "                     'episode_reward_min': -0.8071641430412375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.6943057345360824,\n",
            "                                                       -0.581447326030928,\n",
            "                                                       -0.7507349387886597,\n",
            "                                                       -0.8071641430412375,\n",
            "                                                       -0.5137322809278349,\n",
            "                                                       -0.7055915753865979]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.0936312198137282,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.1390783239664656,\n",
            "                                      'mean_inference_ms': 2.6300325149781867,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2831254668181497}},\n",
            " 'time_since_restore': 132.96911931037903,\n",
            " 'time_this_iter_s': 65.55450129508972,\n",
            " 'time_total_s': 917.3356020450592,\n",
            " 'timers': {'learn_throughput': 66.586,\n",
            "            'learn_time_ms': 60072.853,\n",
            "            'load_throughput': 68146.185,\n",
            "            'load_time_ms': 58.697,\n",
            "            'synch_weights_time_ms': 4.555,\n",
            "            'training_iteration_time_ms': 66478.926},\n",
            " 'timestamp': 1701164252,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 56000,\n",
            " 'training_iteration': 14,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.5855793952941895}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:38:39,385\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthExploreHard', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthExploreHard').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 60000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd15741670>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd56425a30>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.031752586364746094,\n",
            "                       'StateBufferConnector_ms': 0.005047321319580078,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12065887451171875},\n",
            " 'counters': {'num_agent_steps_sampled': 60000,\n",
            "              'num_agent_steps_trained': 60000,\n",
            "              'num_env_steps_sampled': 60000,\n",
            "              'num_env_steps_trained': 60000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-38-39',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.5137322809278349,\n",
            " 'episode_reward_mean': -0.6570624597293815,\n",
            " 'episode_reward_min': -0.8071641430412375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 55,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.6943057345360824,\n",
            "                                   -0.581447326030928,\n",
            "                                   -0.7507349387886597,\n",
            "                                   -0.8071641430412375,\n",
            "                                   -0.5137322809278349,\n",
            "                                   -0.7055915753865979,\n",
            "                                   -0.6943057345360825,\n",
            "                                   -0.705591575386598,\n",
            "                                   -0.5137322809278351,\n",
            "                                   -0.6040190077319588]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.3,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.1135893320524564,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.017640797696476904,\n",
            "                                                           'policy_loss': -0.030791866785335926,\n",
            "                                                           'total_loss': -0.023078784346580505,\n",
            "                                                           'vf_explained_var': -0.9808023937286869,\n",
            "                                                           'vf_loss': 0.002420842970010414},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2295.5}},\n",
            "          'num_agent_steps_sampled': 60000,\n",
            "          'num_agent_steps_trained': 60000,\n",
            "          'num_env_steps_sampled': 60000,\n",
            "          'num_env_steps_trained': 60000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 60000,\n",
            " 'num_agent_steps_trained': 60000,\n",
            " 'num_env_steps_sampled': 60000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 60000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.209473684210526,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09363157711919128,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.1389546139265036,\n",
            "                  'mean_inference_ms': 2.632607140962597,\n",
            "                  'mean_raw_obs_processing_ms': 0.2839307394603325},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.031752586364746094,\n",
            "                                           'StateBufferConnector_ms': 0.005047321319580078,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12065887451171875},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.5137322809278349,\n",
            "                     'episode_reward_mean': -0.6570624597293815,\n",
            "                     'episode_reward_min': -0.8071641430412375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.6943057345360824,\n",
            "                                                       -0.581447326030928,\n",
            "                                                       -0.7507349387886597,\n",
            "                                                       -0.8071641430412375,\n",
            "                                                       -0.5137322809278349,\n",
            "                                                       -0.7055915753865979,\n",
            "                                                       -0.6943057345360825,\n",
            "                                                       -0.705591575386598,\n",
            "                                                       -0.5137322809278351,\n",
            "                                                       -0.6040190077319588]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09363157711919128,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.1389546139265036,\n",
            "                                      'mean_inference_ms': 2.632607140962597,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2839307394603325}},\n",
            " 'time_since_restore': 199.76505947113037,\n",
            " 'time_this_iter_s': 66.79594016075134,\n",
            " 'time_total_s': 984.1315422058105,\n",
            " 'timers': {'learn_throughput': 66.505,\n",
            "            'learn_time_ms': 60146.125,\n",
            "            'load_throughput': 64445.379,\n",
            "            'load_time_ms': 62.068,\n",
            "            'synch_weights_time_ms': 4.98,\n",
            "            'training_iteration_time_ms': 66582.48},\n",
            " 'timestamp': 1701164319,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 60000,\n",
            " 'training_iteration': 15,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.5855793952941895}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 0 Environment LabyrinthExploreHard:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=765981)\u001b[0m 2023-11-28 02:38:43,021\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=765981)\u001b[0m 2023-11-28 02:38:43,021\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:38:43,955\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:38:43,988\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_0_env_LabyrinthExploreMedium/checkpoint_000015\n",
            "2023-11-28 02:38:43,989\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 15, '_timesteps_total': None, '_time_total': 984.1315422058105, '_episodes_total': 55}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 64000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd154eff70>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c834e20>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.02963542938232422,\n",
            "                       'StateBufferConnector_ms': 0.005161762237548828,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.1210331916809082},\n",
            " 'counters': {'num_agent_steps_sampled': 64000,\n",
            "              'num_agent_steps_trained': 64000,\n",
            "              'num_env_steps_sampled': 64000,\n",
            "              'num_env_steps_trained': 64000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-39-50',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.7474524456521737,\n",
            " 'episode_reward_mean': -0.7905789013975154,\n",
            " 'episode_reward_min': -0.8337053571428571,\n",
            " 'episodes_this_iter': 2,\n",
            " 'episodes_total': 57,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                'episode_reward': [-0.8337053571428571, -0.7474524456521737]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.3,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.0501735223236905,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01569518776820088,\n",
            "                                                           'policy_loss': -0.018521902085311952,\n",
            "                                                           'total_loss': -0.01208526137214835,\n",
            "                                                           'vf_explained_var': -0.988900496882777,\n",
            "                                                           'vf_loss': 0.0017280852826129425},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 64000,\n",
            "          'num_agent_steps_trained': 64000,\n",
            "          'num_env_steps_sampled': 64000,\n",
            "          'num_env_steps_trained': 64000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 64000,\n",
            " 'num_agent_steps_trained': 64000,\n",
            " 'num_env_steps_sampled': 64000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 64000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.216842105263158,\n",
            "          'ram_util_percent': 5.106315789473687},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09455226886754987,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.13949208590818726,\n",
            "                  'mean_inference_ms': 2.6791504417163976,\n",
            "                  'mean_raw_obs_processing_ms': 0.2821489669632042},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.02963542938232422,\n",
            "                                           'StateBufferConnector_ms': 0.005161762237548828,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.1210331916809082},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.7474524456521737,\n",
            "                     'episode_reward_mean': -0.7905789013975154,\n",
            "                     'episode_reward_min': -0.8337053571428571,\n",
            "                     'episodes_this_iter': 2,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                                    'episode_reward': [-0.8337053571428571,\n",
            "                                                       -0.7474524456521737]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09455226886754987,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.13949208590818726,\n",
            "                                      'mean_inference_ms': 2.6791504417163976,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2821489669632042}},\n",
            " 'time_since_restore': 66.39993095397949,\n",
            " 'time_this_iter_s': 66.39993095397949,\n",
            " 'time_total_s': 1050.53147315979,\n",
            " 'timers': {'learn_throughput': 66.766,\n",
            "            'learn_time_ms': 59910.871,\n",
            "            'load_throughput': 86785.138,\n",
            "            'load_time_ms': 46.091,\n",
            "            'synch_weights_time_ms': 4.631,\n",
            "            'training_iteration_time_ms': 66393.972},\n",
            " 'timestamp': 1701164390,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 64000,\n",
            " 'training_iteration': 16,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.5987303256988525}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 68000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd154eff70>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd1595ccd0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03143151601155599,\n",
            "                       'StateBufferConnector_ms': 0.0051021575927734375,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12054840723673503},\n",
            " 'counters': {'num_agent_steps_sampled': 68000,\n",
            "              'num_agent_steps_trained': 68000,\n",
            "              'num_env_steps_sampled': 68000,\n",
            "              'num_env_steps_trained': 68000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-40-56',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.7115137325310559,\n",
            " 'episode_reward_mean': -0.784589115877329,\n",
            " 'episode_reward_min': -0.8768318128881987,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 61,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.8337053571428571,\n",
            "                                   -0.7474524456521737,\n",
            "                                   -0.7474524456521736,\n",
            "                                   -0.8768318128881987,\n",
            "                                   -0.7905789013975152,\n",
            "                                   -0.7115137325310559]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.29999999999999993,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 1.0559633677535587,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01855991149463888,\n",
            "                                                           'policy_loss': -0.03481559290654129,\n",
            "                                                           'total_loss': -0.027149779001871745,\n",
            "                                                           'vf_explained_var': -0.9613922641840246,\n",
            "                                                           'vf_loss': 0.002097839377949842},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 68000,\n",
            "          'num_agent_steps_trained': 68000,\n",
            "          'num_env_steps_sampled': 68000,\n",
            "          'num_env_steps_trained': 68000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 68000,\n",
            " 'num_agent_steps_trained': 68000,\n",
            " 'num_env_steps_sampled': 68000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 68000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.12127659574468,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09428451548574686,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.1387590951582299,\n",
            "                  'mean_inference_ms': 2.678866880781752,\n",
            "                  'mean_raw_obs_processing_ms': 0.28351603198405556},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03143151601155599,\n",
            "                                           'StateBufferConnector_ms': 0.0051021575927734375,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12054840723673503},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.7115137325310559,\n",
            "                     'episode_reward_mean': -0.784589115877329,\n",
            "                     'episode_reward_min': -0.8768318128881987,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.8337053571428571,\n",
            "                                                       -0.7474524456521737,\n",
            "                                                       -0.7474524456521736,\n",
            "                                                       -0.8768318128881987,\n",
            "                                                       -0.7905789013975152,\n",
            "                                                       -0.7115137325310559]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09428451548574686,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.1387590951582299,\n",
            "                                      'mean_inference_ms': 2.678866880781752,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28351603198405556}},\n",
            " 'time_since_restore': 132.0483522415161,\n",
            " 'time_this_iter_s': 65.64842128753662,\n",
            " 'time_total_s': 1116.1798944473267,\n",
            " 'timers': {'learn_throughput': 67.176,\n",
            "            'learn_time_ms': 59544.965,\n",
            "            'load_throughput': 112340.909,\n",
            "            'load_time_ms': 35.606,\n",
            "            'synch_weights_time_ms': 5.168,\n",
            "            'training_iteration_time_ms': 66017.975},\n",
            " 'timestamp': 1701164456,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 68000,\n",
            " 'training_iteration': 17,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.5987303256988525}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:42:04,287\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthEscapeEasy', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthEscapeEasy').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 72000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd154eff70>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd564824c0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03213167190551758,\n",
            "                       'StateBufferConnector_ms': 0.005116462707519531,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12063264846801758},\n",
            " 'counters': {'num_agent_steps_sampled': 72000,\n",
            "              'num_agent_steps_trained': 72000,\n",
            "              'num_env_steps_sampled': 72000,\n",
            "              'num_env_steps_trained': 72000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-42-04',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.7115137325310559,\n",
            " 'episode_reward_mean': -0.8071107094332298,\n",
            " 'episode_reward_min': -0.8768318128881987,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 65,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.8337053571428571,\n",
            "                                   -0.7474524456521737,\n",
            "                                   -0.7474524456521736,\n",
            "                                   -0.8768318128881987,\n",
            "                                   -0.7905789013975152,\n",
            "                                   -0.7115137325310559,\n",
            "                                   -0.8768318128881987,\n",
            "                                   -0.7618279309006211,\n",
            "                                   -0.8480808423913043,\n",
            "                                   -0.8768318128881987]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.3,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.9681714910332875,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.0161481336829824,\n",
            "                                                           'policy_loss': -0.04819750866842686,\n",
            "                                                           'total_loss': -0.041600705980153016,\n",
            "                                                           'vf_explained_var': -0.9633409341336578,\n",
            "                                                           'vf_loss': 0.001752361775030412},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2295.5}},\n",
            "          'num_agent_steps_sampled': 72000,\n",
            "          'num_agent_steps_trained': 72000,\n",
            "          'num_env_steps_sampled': 72000,\n",
            "          'num_env_steps_trained': 72000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 72000,\n",
            " 'num_agent_steps_trained': 72000,\n",
            " 'num_env_steps_sampled': 72000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 72000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.077319587628866,\n",
            "          'ram_util_percent': 5.100000000000001},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09413864383084129,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.13841408206023503,\n",
            "                  'mean_inference_ms': 2.678616520641909,\n",
            "                  'mean_raw_obs_processing_ms': 0.28399760152632414},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03213167190551758,\n",
            "                                           'StateBufferConnector_ms': 0.005116462707519531,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12063264846801758},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.7115137325310559,\n",
            "                     'episode_reward_mean': -0.8071107094332298,\n",
            "                     'episode_reward_min': -0.8768318128881987,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.8337053571428571,\n",
            "                                                       -0.7474524456521737,\n",
            "                                                       -0.7474524456521736,\n",
            "                                                       -0.8768318128881987,\n",
            "                                                       -0.7905789013975152,\n",
            "                                                       -0.7115137325310559,\n",
            "                                                       -0.8768318128881987,\n",
            "                                                       -0.7618279309006211,\n",
            "                                                       -0.8480808423913043,\n",
            "                                                       -0.8768318128881987]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09413864383084129,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.13841408206023503,\n",
            "                                      'mean_inference_ms': 2.678616520641909,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28399760152632414}},\n",
            " 'time_since_restore': 200.18277955055237,\n",
            " 'time_this_iter_s': 68.13442730903625,\n",
            " 'time_total_s': 1184.314321756363,\n",
            " 'timers': {'learn_throughput': 66.408,\n",
            "            'learn_time_ms': 60233.383,\n",
            "            'load_throughput': 89847.619,\n",
            "            'load_time_ms': 44.52,\n",
            "            'synch_weights_time_ms': 5.009,\n",
            "            'training_iteration_time_ms': 66721.507},\n",
            " 'timestamp': 1701164524,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 72000,\n",
            " 'training_iteration': 18,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.5987303256988525}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 1 Environment LabyrinthEscapeEasy:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=777454)\u001b[0m 2023-11-28 02:42:08,012\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=777454)\u001b[0m 2023-11-28 02:42:08,012\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:42:08,908\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:42:08,943\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_0_env_LabyrinthExploreHard/checkpoint_000018\n",
            "2023-11-28 02:42:08,943\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 18, '_timesteps_total': None, '_time_total': 1184.314321756363, '_episodes_total': 65}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 76000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd157415e0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd5647db80>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03127455711364746,\n",
            "                       'StateBufferConnector_ms': 0.005048513412475586,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12298226356506348},\n",
            " 'counters': {'num_agent_steps_sampled': 76000,\n",
            "              'num_agent_steps_trained': 76000,\n",
            "              'num_env_steps_sampled': 76000,\n",
            "              'num_env_steps_trained': 76000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-43-17',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 639.5,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.8759765625,\n",
            " 'episode_reward_mean': -0.12451171875,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 69,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [127, 385, 1023, 1023],\n",
            "                'episode_reward': [0.8759765625,\n",
            "                                   0.6240234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.3,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.9290143848747335,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.014773814212743654,\n",
            "                                                           'policy_loss': -0.006601724517281337,\n",
            "                                                           'total_loss': 0.015544008111120552,\n",
            "                                                           'vf_explained_var': -0.9711643348457992,\n",
            "                                                           'vf_loss': 0.01771358708808479},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 76000,\n",
            "          'num_agent_steps_trained': 76000,\n",
            "          'num_env_steps_sampled': 76000,\n",
            "          'num_env_steps_trained': 76000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 76000,\n",
            " 'num_agent_steps_trained': 76000,\n",
            " 'num_env_steps_sampled': 76000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 76000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.275510204081632,\n",
            "          'ram_util_percent': 5.106122448979593},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09455161354411905,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11661248109389519,\n",
            "                  'mean_inference_ms': 2.6426640586338297,\n",
            "                  'mean_raw_obs_processing_ms': 0.2860023580986759},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03127455711364746,\n",
            "                                           'StateBufferConnector_ms': 0.005048513412475586,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12298226356506348},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 639.5,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.8759765625,\n",
            "                     'episode_reward_mean': -0.12451171875,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [127, 385, 1023, 1023],\n",
            "                                    'episode_reward': [0.8759765625,\n",
            "                                                       0.6240234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09455161354411905,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11661248109389519,\n",
            "                                      'mean_inference_ms': 2.6426640586338297,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2860023580986759}},\n",
            " 'time_since_restore': 68.05668997764587,\n",
            " 'time_this_iter_s': 68.05668997764587,\n",
            " 'time_total_s': 1252.3710117340088,\n",
            " 'timers': {'learn_throughput': 64.854,\n",
            "            'learn_time_ms': 61677.024,\n",
            "            'load_throughput': 255256.074,\n",
            "            'load_time_ms': 15.671,\n",
            "            'synch_weights_time_ms': 6.662,\n",
            "            'training_iteration_time_ms': 68050.971},\n",
            " 'timestamp': 1701164597,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 76000,\n",
            " 'training_iteration': 19,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.651302337646484}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 80000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd157415e0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c834e20>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03209710121154785,\n",
            "                       'StateBufferConnector_ms': 0.004976987838745117,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12356936931610107},\n",
            " 'counters': {'num_agent_steps_sampled': 80000,\n",
            "              'num_agent_steps_trained': 80000,\n",
            "              'num_env_steps_sampled': 80000,\n",
            "              'num_env_steps_trained': 80000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-44-23',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 801.875,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.8759765625,\n",
            " 'episode_reward_mean': -0.4080810546875,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 73,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [127,\n",
            "                                    385,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    788,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [0.8759765625,\n",
            "                                   0.6240234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   0.23046875,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.29999999999999993,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.8677285013596217,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01848028633812242,\n",
            "                                                           'policy_loss': -0.02175236779368586,\n",
            "                                                           'total_loss': -0.007542690485715866,\n",
            "                                                           'vf_explained_var': -0.960244699716568,\n",
            "                                                           'vf_loss': 0.008665591209751761},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 80000,\n",
            "          'num_agent_steps_trained': 80000,\n",
            "          'num_env_steps_sampled': 80000,\n",
            "          'num_env_steps_trained': 80000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 80000,\n",
            " 'num_agent_steps_trained': 80000,\n",
            " 'num_env_steps_sampled': 80000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 80000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.060638297872341,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09431409114151129,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11641044527922705,\n",
            "                  'mean_inference_ms': 2.6449154378404325,\n",
            "                  'mean_raw_obs_processing_ms': 0.2860070680971718},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03209710121154785,\n",
            "                                           'StateBufferConnector_ms': 0.004976987838745117,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12356936931610107},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 801.875,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.8759765625,\n",
            "                     'episode_reward_mean': -0.4080810546875,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [127,\n",
            "                                                        385,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        788,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [0.8759765625,\n",
            "                                                       0.6240234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       0.23046875,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09431409114151129,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11641044527922705,\n",
            "                                      'mean_inference_ms': 2.6449154378404325,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2860070680971718}},\n",
            " 'time_since_restore': 134.6456696987152,\n",
            " 'time_this_iter_s': 66.58897972106934,\n",
            " 'time_total_s': 1318.9599914550781,\n",
            " 'timers': {'learn_throughput': 65.666,\n",
            "            'learn_time_ms': 60914.198,\n",
            "            'load_throughput': 167953.55,\n",
            "            'load_time_ms': 23.816,\n",
            "            'synch_weights_time_ms': 5.756,\n",
            "            'training_iteration_time_ms': 67317.388},\n",
            " 'timestamp': 1701164663,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 80000,\n",
            " 'training_iteration': 20,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.651302337646484}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:45:31,917\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthEscapeMedium', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthEscapeMedium').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 84000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd157415e0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd154d4280>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.032335519790649414,\n",
            "                       'StateBufferConnector_ms': 0.004933277765909831,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12289683024088542},\n",
            " 'counters': {'num_agent_steps_sampled': 84000,\n",
            "              'num_agent_steps_trained': 84000,\n",
            "              'num_env_steps_sampled': 84000,\n",
            "              'num_env_steps_trained': 84000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-45-31',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 875.5833333333334,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.8759765625,\n",
            " 'episode_reward_mean': -0.6050618489583334,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 77,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [127,\n",
            "                                    385,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    788,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [0.8759765625,\n",
            "                                   0.6240234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   0.23046875,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.29999999999999993,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.801592050327195,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.016136355466797897,\n",
            "                                                           'policy_loss': -0.03484481380631526,\n",
            "                                                           'total_loss': -0.02820818500800265,\n",
            "                                                           'vf_explained_var': -0.9913496986362669,\n",
            "                                                           'vf_loss': 0.0017957217043537337},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2280.5}},\n",
            "          'num_agent_steps_sampled': 84000,\n",
            "          'num_agent_steps_trained': 84000,\n",
            "          'num_env_steps_sampled': 84000,\n",
            "          'num_env_steps_trained': 84000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 84000,\n",
            " 'num_agent_steps_trained': 84000,\n",
            " 'num_env_steps_sampled': 84000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 84000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.123469387755101,\n",
            "          'ram_util_percent': 5.100000000000001},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09421754902714707,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11627320476911206,\n",
            "                  'mean_inference_ms': 2.6455007376005195,\n",
            "                  'mean_raw_obs_processing_ms': 0.28617550077723847},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.032335519790649414,\n",
            "                                           'StateBufferConnector_ms': 0.004933277765909831,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12289683024088542},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 875.5833333333334,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.8759765625,\n",
            "                     'episode_reward_mean': -0.6050618489583334,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [127,\n",
            "                                                        385,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        788,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [0.8759765625,\n",
            "                                                       0.6240234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       0.23046875,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09421754902714707,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11627320476911206,\n",
            "                                      'mean_inference_ms': 2.6455007376005195,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28617550077723847}},\n",
            " 'time_since_restore': 202.8401210308075,\n",
            " 'time_this_iter_s': 68.19445133209229,\n",
            " 'time_total_s': 1387.1544427871704,\n",
            " 'timers': {'learn_throughput': 65.361,\n",
            "            'learn_time_ms': 61198.297,\n",
            "            'load_throughput': 142859.793,\n",
            "            'load_time_ms': 27.999,\n",
            "            'synch_weights_time_ms': 5.525,\n",
            "            'training_iteration_time_ms': 67607.645},\n",
            " 'timestamp': 1701164731,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 84000,\n",
            " 'training_iteration': 21,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.651302337646484}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 1 Environment LabyrinthEscapeMedium:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=788811)\u001b[0m 2023-11-28 02:45:35,571\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=788811)\u001b[0m 2023-11-28 02:45:35,572\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:45:36,492\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:45:36,525\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_1_env_LabyrinthEscapeEasy/checkpoint_000021\n",
            "2023-11-28 02:45:36,526\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 21, '_timesteps_total': None, '_time_total': 1387.1544427871704, '_episodes_total': 77}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 88000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd158a2550>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd1595c760>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03153085708618164,\n",
            "                       'StateBufferConnector_ms': 0.004827976226806641,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.1225590705871582},\n",
            " 'counters': {'num_agent_steps_sampled': 88000,\n",
            "              'num_agent_steps_trained': 88000,\n",
            "              'num_env_steps_sampled': 88000,\n",
            "              'num_env_steps_trained': 88000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-46-44',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 947.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.2392578125,\n",
            " 'episode_reward_mean': -0.4248046875,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 81,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 779, 963, 1023],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   0.2392578125,\n",
            "                                   0.0595703125,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.3,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.8225395832010495,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.014087185227400633,\n",
            "                                                           'policy_loss': -0.030118679215190233,\n",
            "                                                           'total_loss': -0.002777629433780588,\n",
            "                                                           'vf_explained_var': -0.9541849407457537,\n",
            "                                                           'vf_loss': 0.023114891608761404},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 88000,\n",
            "          'num_agent_steps_trained': 88000,\n",
            "          'num_env_steps_sampled': 88000,\n",
            "          'num_env_steps_trained': 88000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 88000,\n",
            " 'num_agent_steps_trained': 88000,\n",
            " 'num_env_steps_sampled': 88000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 88000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.3775510204081627,\n",
            "          'ram_util_percent': 5.106122448979593},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09557064147903466,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11607457970691168,\n",
            "                  'mean_inference_ms': 2.6762709505614013,\n",
            "                  'mean_raw_obs_processing_ms': 0.28537726890796544},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03153085708618164,\n",
            "                                           'StateBufferConnector_ms': 0.004827976226806641,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.1225590705871582},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 947.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.2392578125,\n",
            "                     'episode_reward_mean': -0.4248046875,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 779, 963, 1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       0.2392578125,\n",
            "                                                       0.0595703125,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09557064147903466,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11607457970691168,\n",
            "                                      'mean_inference_ms': 2.6762709505614013,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28537726890796544}},\n",
            " 'time_since_restore': 68.1261830329895,\n",
            " 'time_this_iter_s': 68.1261830329895,\n",
            " 'time_total_s': 1455.28062582016,\n",
            " 'timers': {'learn_throughput': 64.873,\n",
            "            'learn_time_ms': 61658.975,\n",
            "            'load_throughput': 64793.657,\n",
            "            'load_time_ms': 61.734,\n",
            "            'synch_weights_time_ms': 5.731,\n",
            "            'training_iteration_time_ms': 68119.991},\n",
            " 'timestamp': 1701164804,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 88000,\n",
            " 'training_iteration': 22,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.603092670440674}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 92000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd158a2550>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbc342f1970>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03152574811662946,\n",
            "                       'StateBufferConnector_ms': 0.004890986851283482,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12230191911969866},\n",
            " 'counters': {'num_agent_steps_sampled': 92000,\n",
            "              'num_agent_steps_trained': 92000,\n",
            "              'num_env_steps_sampled': 92000,\n",
            "              'num_env_steps_trained': 92000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-47-51',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 979.5714285714286,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.2392578125,\n",
            " 'episode_reward_mean': -0.6708984375,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 3,\n",
            " 'episodes_total': 84,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 779, 963, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   0.2392578125,\n",
            "                                   0.0595703125,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.29999999999999993,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.957342879374822,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01601176348100934,\n",
            "                                                           'policy_loss': -0.017592778818474875,\n",
            "                                                           'total_loss': -0.009709818483226829,\n",
            "                                                           'vf_explained_var': -0.9853049741188685,\n",
            "                                                           'vf_loss': 0.003079430673387833},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 92000,\n",
            "          'num_agent_steps_trained': 92000,\n",
            "          'num_env_steps_sampled': 92000,\n",
            "          'num_env_steps_trained': 92000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 92000,\n",
            " 'num_agent_steps_trained': 92000,\n",
            " 'num_env_steps_sampled': 92000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 92000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 2.9652631578947375,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09516395470766889,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11567547785271859,\n",
            "                  'mean_inference_ms': 2.677130679784134,\n",
            "                  'mean_raw_obs_processing_ms': 0.2854579523793081},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03152574811662946,\n",
            "                                           'StateBufferConnector_ms': 0.004890986851283482,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12230191911969866},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 979.5714285714286,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.2392578125,\n",
            "                     'episode_reward_mean': -0.6708984375,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 3,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        779,\n",
            "                                                        963,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       0.2392578125,\n",
            "                                                       0.0595703125,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09516395470766889,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11567547785271859,\n",
            "                                      'mean_inference_ms': 2.677130679784134,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2854579523793081}},\n",
            " 'time_since_restore': 135.34801721572876,\n",
            " 'time_this_iter_s': 67.22183418273926,\n",
            " 'time_total_s': 1522.5024600028992,\n",
            " 'timers': {'learn_throughput': 65.354,\n",
            "            'learn_time_ms': 61205.455,\n",
            "            'load_throughput': 67820.71,\n",
            "            'load_time_ms': 58.979,\n",
            "            'synch_weights_time_ms': 4.801,\n",
            "            'training_iteration_time_ms': 67668.119},\n",
            " 'timestamp': 1701164871,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 92000,\n",
            " 'training_iteration': 23,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.603092670440674}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:48:55,894\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthEscapeHard', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthEscapeHard').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 96000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd158a2550>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd5648a6d0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03232739188454368,\n",
            "                       'StateBufferConnector_ms': 0.0049461017955433235,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.1233816146850586},\n",
            " 'counters': {'num_agent_steps_sampled': 96000,\n",
            "              'num_agent_steps_trained': 96000,\n",
            "              'num_env_steps_sampled': 96000,\n",
            "              'num_env_steps_trained': 96000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-48-55',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 995.3636363636364,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 0.2392578125,\n",
            " 'episode_reward_mean': -0.7902166193181818,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 88,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    779,\n",
            "                                    963,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   0.2392578125,\n",
            "                                   0.0595703125,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.29999999999999993,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.9366189963287778,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.02125650214865244,\n",
            "                                                           'policy_loss': -0.0349016962841981,\n",
            "                                                           'total_loss': -0.02660009794972009,\n",
            "                                                           'vf_explained_var': -1.0,\n",
            "                                                           'vf_loss': 0.001924647304889125},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2280.5}},\n",
            "          'num_agent_steps_sampled': 96000,\n",
            "          'num_agent_steps_trained': 96000,\n",
            "          'num_env_steps_sampled': 96000,\n",
            "          'num_env_steps_trained': 96000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 96000,\n",
            " 'num_agent_steps_trained': 96000,\n",
            " 'num_env_steps_sampled': 96000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 96000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 2.8597826086956526,\n",
            "          'ram_util_percent': 5.100000000000001},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09503281048443378,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11536399045144229,\n",
            "                  'mean_inference_ms': 2.6754912225682146,\n",
            "                  'mean_raw_obs_processing_ms': 0.2857041704772866},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03232739188454368,\n",
            "                                           'StateBufferConnector_ms': 0.0049461017955433235,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.1233816146850586},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 995.3636363636364,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 0.2392578125,\n",
            "                     'episode_reward_mean': -0.7902166193181818,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        779,\n",
            "                                                        963,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       0.2392578125,\n",
            "                                                       0.0595703125,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09503281048443378,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11536399045144229,\n",
            "                                      'mean_inference_ms': 2.6754912225682146,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2857041704772866}},\n",
            " 'time_since_restore': 199.24803924560547,\n",
            " 'time_this_iter_s': 63.90002202987671,\n",
            " 'time_total_s': 1586.4024820327759,\n",
            " 'timers': {'learn_throughput': 66.717,\n",
            "            'learn_time_ms': 59954.969,\n",
            "            'load_throughput': 68511.337,\n",
            "            'load_time_ms': 58.384,\n",
            "            'synch_weights_time_ms': 5.283,\n",
            "            'training_iteration_time_ms': 66409.891},\n",
            " 'timestamp': 1701164935,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 96000,\n",
            " 'training_iteration': 24,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.603092670440674}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 1 Environment LabyrinthEscapeHard:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=800152)\u001b[0m 2023-11-28 02:48:59,545\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=800152)\u001b[0m 2023-11-28 02:48:59,546\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:49:00,462\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:49:00,493\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_1_env_LabyrinthEscapeMedium/checkpoint_000024\n",
            "2023-11-28 02:49:00,493\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 24, '_timesteps_total': None, '_time_total': 1586.4024820327759, '_episodes_total': 88}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 100000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd158629d0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c25dfa0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030243396759033203,\n",
            "                       'StateBufferConnector_ms': 0.0049114227294921875,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12148618698120117},\n",
            " 'counters': {'num_agent_steps_sampled': 100000,\n",
            "              'num_agent_steps_trained': 100000,\n",
            "              'num_env_steps_sampled': 100000,\n",
            "              'num_env_steps_trained': 100000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-50-08',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.9990234375,\n",
            " 'episode_reward_mean': -0.9990234375,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 2,\n",
            " 'episodes_total': 90,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                'episode_reward': [-0.9990234375, -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.4500000000000001,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.90424427101689,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.012974724484702556,\n",
            "                                                           'policy_loss': -0.05938980220666816,\n",
            "                                                           'total_loss': -0.05235748643516212,\n",
            "                                                           'vf_explained_var': -0.9986404445222629,\n",
            "                                                           'vf_loss': 0.0011936905017117618},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 100000,\n",
            "          'num_agent_steps_trained': 100000,\n",
            "          'num_env_steps_sampled': 100000,\n",
            "          'num_env_steps_trained': 100000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 100000,\n",
            " 'num_agent_steps_trained': 100000,\n",
            " 'num_env_steps_sampled': 100000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 100000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.141237113402062,\n",
            "          'ram_util_percent': 5.10618556701031},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09206543559732586,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11648034406030017,\n",
            "                  'mean_inference_ms': 2.596838720913591,\n",
            "                  'mean_raw_obs_processing_ms': 0.28060425048706117},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030243396759033203,\n",
            "                                           'StateBufferConnector_ms': 0.0049114227294921875,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12148618698120117},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.9990234375,\n",
            "                     'episode_reward_mean': -0.9990234375,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 2,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09206543559732586,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11648034406030017,\n",
            "                                      'mean_inference_ms': 2.596838720913591,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28060425048706117}},\n",
            " 'time_since_restore': 67.52233004570007,\n",
            " 'time_this_iter_s': 67.52233004570007,\n",
            " 'time_total_s': 1653.924812078476,\n",
            " 'timers': {'learn_throughput': 65.367,\n",
            "            'learn_time_ms': 61192.66,\n",
            "            'load_throughput': 67681.176,\n",
            "            'load_time_ms': 59.101,\n",
            "            'synch_weights_time_ms': 8.918,\n",
            "            'training_iteration_time_ms': 67517.33},\n",
            " 'timestamp': 1701165008,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 100000,\n",
            " 'training_iteration': 25,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.592655181884766}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 104000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd158629d0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd5647b5b0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03154277801513672,\n",
            "                       'StateBufferConnector_ms': 0.004887580871582031,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12187957763671875},\n",
            " 'counters': {'num_agent_steps_sampled': 104000,\n",
            "              'num_agent_steps_trained': 104000,\n",
            "              'num_env_steps_sampled': 104000,\n",
            "              'num_env_steps_trained': 104000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-51-13',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.9990234375,\n",
            " 'episode_reward_mean': -0.9990234375,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 94,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.4500000000000001,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.9419240057468414,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01761783983635218,\n",
            "                                                           'policy_loss': -0.05836471030074689,\n",
            "                                                           'total_loss': -0.049279271773993966,\n",
            "                                                           'vf_explained_var': -0.9565789292256037,\n",
            "                                                           'vf_loss': 0.0011574115028714813},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 104000,\n",
            "          'num_agent_steps_trained': 104000,\n",
            "          'num_env_steps_sampled': 104000,\n",
            "          'num_env_steps_trained': 104000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 104000,\n",
            " 'num_agent_steps_trained': 104000,\n",
            " 'num_env_steps_sampled': 104000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 104000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.082795698924732,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09207157931715178,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.1162635189771431,\n",
            "                  'mean_inference_ms': 2.607106846033479,\n",
            "                  'mean_raw_obs_processing_ms': 0.28290669660572537},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03154277801513672,\n",
            "                                           'StateBufferConnector_ms': 0.004887580871582031,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12187957763671875},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.9990234375,\n",
            "                     'episode_reward_mean': -0.9990234375,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09207157931715178,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.1162635189771431,\n",
            "                                      'mean_inference_ms': 2.607106846033479,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28290669660572537}},\n",
            " 'time_since_restore': 133.12607765197754,\n",
            " 'time_this_iter_s': 65.60374760627747,\n",
            " 'time_total_s': 1719.5285596847534,\n",
            " 'timers': {'learn_throughput': 66.426,\n",
            "            'learn_time_ms': 60217.035,\n",
            "            'load_throughput': 68917.96,\n",
            "            'load_time_ms': 58.04,\n",
            "            'synch_weights_time_ms': 6.747,\n",
            "            'training_iteration_time_ms': 66556.946},\n",
            " 'timestamp': 1701165073,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 104000,\n",
            " 'training_iteration': 26,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.592655181884766}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:52:19,315\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthExploreEasy', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthExploreEasy').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 108000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthEscapeHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd158629d0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd5647e5e0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03174304962158203,\n",
            "                       'StateBufferConnector_ms': 0.004909038543701172,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12236595153808594},\n",
            " 'counters': {'num_agent_steps_sampled': 108000,\n",
            "              'num_agent_steps_trained': 108000,\n",
            "              'num_env_steps_sampled': 108000,\n",
            "              'num_env_steps_trained': 108000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-52-19',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.9990234375,\n",
            " 'episode_reward_mean': -0.9990234375,\n",
            " 'episode_reward_min': -0.9990234375,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 98,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375,\n",
            "                                   -0.9990234375]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.4500000000000001,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.9153807242070475,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01596567010570574,\n",
            "                                                           'policy_loss': -0.041896951855510796,\n",
            "                                                           'total_loss': -0.03361079461311781,\n",
            "                                                           'vf_explained_var': -0.970028843963018,\n",
            "                                                           'vf_loss': 0.0011016048554528845},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2295.5}},\n",
            "          'num_agent_steps_sampled': 108000,\n",
            "          'num_agent_steps_trained': 108000,\n",
            "          'num_env_steps_sampled': 108000,\n",
            "          'num_env_steps_trained': 108000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 108000,\n",
            " 'num_agent_steps_trained': 108000,\n",
            " 'num_env_steps_sampled': 108000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 108000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.2638297872340427,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09211175669451507,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.11606960730660285,\n",
            "                  'mean_inference_ms': 2.610741550817421,\n",
            "                  'mean_raw_obs_processing_ms': 0.28374547657755134},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03174304962158203,\n",
            "                                           'StateBufferConnector_ms': 0.004909038543701172,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12236595153808594},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.9990234375,\n",
            "                     'episode_reward_mean': -0.9990234375,\n",
            "                     'episode_reward_min': -0.9990234375,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375,\n",
            "                                                       -0.9990234375]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09211175669451507,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.11606960730660285,\n",
            "                                      'mean_inference_ms': 2.610741550817421,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28374547657755134}},\n",
            " 'time_since_restore': 198.71012330055237,\n",
            " 'time_this_iter_s': 65.58404564857483,\n",
            " 'time_total_s': 1785.1126053333282,\n",
            " 'timers': {'learn_throughput': 66.794,\n",
            "            'learn_time_ms': 59885.648,\n",
            "            'load_throughput': 69077.101,\n",
            "            'load_time_ms': 57.906,\n",
            "            'synch_weights_time_ms': 6.9,\n",
            "            'training_iteration_time_ms': 66230.607},\n",
            " 'timestamp': 1701165139,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 108000,\n",
            " 'training_iteration': 27,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.592655181884766}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 1 Environment LabyrinthExploreEasy:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=811605)\u001b[0m 2023-11-28 02:52:22,971\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=811605)\u001b[0m 2023-11-28 02:52:22,972\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:52:23,864\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:52:23,896\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_1_env_LabyrinthEscapeHard/checkpoint_000027\n",
            "2023-11-28 02:52:23,897\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 27, '_timesteps_total': None, '_time_total': 1785.1126053333282, '_episodes_total': 98}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 112000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd565da940>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd564742b0>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030565261840820312,\n",
            "                       'StateBufferConnector_ms': 0.005185604095458984,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12259483337402344},\n",
            " 'counters': {'num_agent_steps_sampled': 112000,\n",
            "              'num_agent_steps_trained': 112000,\n",
            "              'num_env_steps_sampled': 112000,\n",
            "              'num_env_steps_trained': 112000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-53-29',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.27194276147959195,\n",
            " 'episode_reward_mean': -0.4750976562500001,\n",
            " 'episode_reward_min': -0.6782525510204083,\n",
            " 'episodes_this_iter': 2,\n",
            " 'episodes_total': 100,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                'episode_reward': [-0.27194276147959195, -0.6782525510204083]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.4500000000000001,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.9187720967236386,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.017464254574129607,\n",
            "                                                           'policy_loss': -0.05927041530288676,\n",
            "                                                           'total_loss': -0.04831316961796694,\n",
            "                                                           'vf_explained_var': -0.9681374181983291,\n",
            "                                                           'vf_loss': 0.0030983322899618376},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 112000,\n",
            "          'num_agent_steps_trained': 112000,\n",
            "          'num_env_steps_sampled': 112000,\n",
            "          'num_env_steps_trained': 112000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 112000,\n",
            " 'num_agent_steps_trained': 112000,\n",
            " 'num_env_steps_sampled': 112000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 112000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.224468085106383,\n",
            "          'ram_util_percent': 5.106382978723406},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09503500393663031,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.14055716520783187,\n",
            "                  'mean_inference_ms': 2.6620135552760424,\n",
            "                  'mean_raw_obs_processing_ms': 0.28460243831331405},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030565261840820312,\n",
            "                                           'StateBufferConnector_ms': 0.005185604095458984,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12259483337402344},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.27194276147959195,\n",
            "                     'episode_reward_mean': -0.4750976562500001,\n",
            "                     'episode_reward_min': -0.6782525510204083,\n",
            "                     'episodes_this_iter': 2,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                                    'episode_reward': [-0.27194276147959195,\n",
            "                                                       -0.6782525510204083]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09503500393663031,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.14055716520783187,\n",
            "                                      'mean_inference_ms': 2.6620135552760424,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28460243831331405}},\n",
            " 'time_since_restore': 65.69740843772888,\n",
            " 'time_this_iter_s': 65.69740843772888,\n",
            " 'time_total_s': 1850.8100137710571,\n",
            " 'timers': {'learn_throughput': 67.61,\n",
            "            'learn_time_ms': 59162.546,\n",
            "            'load_throughput': 69759.734,\n",
            "            'load_time_ms': 57.34,\n",
            "            'synch_weights_time_ms': 5.351,\n",
            "            'training_iteration_time_ms': 65692.352},\n",
            " 'timestamp': 1701165209,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 112000,\n",
            " 'training_iteration': 28,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.575826644897461}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 116000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd565da940>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c8fc250>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03227392832438151,\n",
            "                       'StateBufferConnector_ms': 0.005125999450683594,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12292861938476562},\n",
            " 'counters': {'num_agent_steps_sampled': 116000,\n",
            "              'num_agent_steps_trained': 116000,\n",
            "              'num_env_steps_sampled': 116000,\n",
            "              'num_env_steps_trained': 116000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-54-34',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.20778858418367332,\n",
            " 'episode_reward_mean': -0.5570724383503401,\n",
            " 'episode_reward_min': -0.7851761798469388,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 104,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.27194276147959195,\n",
            "                                   -0.6782525510204083,\n",
            "                                   -0.7851761798469385,\n",
            "                                   -0.6140983737244898,\n",
            "                                   -0.20778858418367332,\n",
            "                                   -0.7851761798469388]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.4500000000000001,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.7156247830059793,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.016651880151900212,\n",
            "                                                           'policy_loss': 0.00998789401517974,\n",
            "                                                           'total_loss': 0.01908967587682936,\n",
            "                                                           'vf_explained_var': -0.980465656419595,\n",
            "                                                           'vf_loss': 0.0016084366866319518},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 116000,\n",
            "          'num_agent_steps_trained': 116000,\n",
            "          'num_env_steps_sampled': 116000,\n",
            "          'num_env_steps_trained': 116000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 116000,\n",
            " 'num_agent_steps_trained': 116000,\n",
            " 'num_env_steps_sampled': 116000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 116000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.1548387096774193,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.0946427089656292,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.1399045795898907,\n",
            "                  'mean_inference_ms': 2.6616074032418635,\n",
            "                  'mean_raw_obs_processing_ms': 0.28550032507157774},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03227392832438151,\n",
            "                                           'StateBufferConnector_ms': 0.005125999450683594,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12292861938476562},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.20778858418367332,\n",
            "                     'episode_reward_mean': -0.5570724383503401,\n",
            "                     'episode_reward_min': -0.7851761798469388,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.27194276147959195,\n",
            "                                                       -0.6782525510204083,\n",
            "                                                       -0.7851761798469385,\n",
            "                                                       -0.6140983737244898,\n",
            "                                                       -0.20778858418367332,\n",
            "                                                       -0.7851761798469388]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.0946427089656292,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.1399045795898907,\n",
            "                                      'mean_inference_ms': 2.6616074032418635,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28550032507157774}},\n",
            " 'time_since_restore': 130.8395869731903,\n",
            " 'time_this_iter_s': 65.14217853546143,\n",
            " 'time_total_s': 1915.9521923065186,\n",
            " 'timers': {'learn_throughput': 67.925,\n",
            "            'learn_time_ms': 58888.496,\n",
            "            'load_throughput': 71465.394,\n",
            "            'load_time_ms': 55.971,\n",
            "            'synch_weights_time_ms': 5.579,\n",
            "            'training_iteration_time_ms': 65414.112},\n",
            " 'timestamp': 1701165274,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 116000,\n",
            " 'training_iteration': 29,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.575826644897461}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:55:42,488\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthExploreMedium', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthExploreMedium').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 120000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreEasy',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd565da940>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd56335250>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.032405853271484375,\n",
            "                       'StateBufferConnector_ms': 0.005080699920654297,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12310504913330078},\n",
            " 'counters': {'num_agent_steps_sampled': 120000,\n",
            "              'num_agent_steps_trained': 120000,\n",
            "              'num_env_steps_sampled': 120000,\n",
            "              'num_env_steps_trained': 120000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-55-42',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.20778858418367332,\n",
            " 'episode_reward_mean': -0.6376215720663265,\n",
            " 'episode_reward_min': -0.8707150829081632,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 108,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.27194276147959195,\n",
            "                                   -0.6782525510204083,\n",
            "                                   -0.7851761798469385,\n",
            "                                   -0.6140983737244898,\n",
            "                                   -0.20778858418367332,\n",
            "                                   -0.7851761798469388,\n",
            "                                   -0.8707150829081632,\n",
            "                                   -0.7210220025510204,\n",
            "                                   -0.8065609056122448,\n",
            "                                   -0.635483099489796]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.4500000000000001,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.8362219011270872,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.019756503873364265,\n",
            "                                                           'policy_loss': -0.05311921285865929,\n",
            "                                                           'total_loss': -0.04210518605165905,\n",
            "                                                           'vf_explained_var': -0.9666957529321794,\n",
            "                                                           'vf_loss': 0.0021236006818306182},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2295.5}},\n",
            "          'num_agent_steps_sampled': 120000,\n",
            "          'num_agent_steps_trained': 120000,\n",
            "          'num_env_steps_sampled': 120000,\n",
            "          'num_env_steps_trained': 120000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 120000,\n",
            " 'num_agent_steps_trained': 120000,\n",
            " 'num_env_steps_sampled': 120000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 120000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.11340206185567,\n",
            "          'ram_util_percent': 5.100000000000001},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09451349623472324,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.13964634649852434,\n",
            "                  'mean_inference_ms': 2.662140202891597,\n",
            "                  'mean_raw_obs_processing_ms': 0.28589377877274574},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.032405853271484375,\n",
            "                                           'StateBufferConnector_ms': 0.005080699920654297,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12310504913330078},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.20778858418367332,\n",
            "                     'episode_reward_mean': -0.6376215720663265,\n",
            "                     'episode_reward_min': -0.8707150829081632,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.27194276147959195,\n",
            "                                                       -0.6782525510204083,\n",
            "                                                       -0.7851761798469385,\n",
            "                                                       -0.6140983737244898,\n",
            "                                                       -0.20778858418367332,\n",
            "                                                       -0.7851761798469388,\n",
            "                                                       -0.8707150829081632,\n",
            "                                                       -0.7210220025510204,\n",
            "                                                       -0.8065609056122448,\n",
            "                                                       -0.635483099489796]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09451349623472324,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.13964634649852434,\n",
            "                                      'mean_inference_ms': 2.662140202891597,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28589377877274574}},\n",
            " 'time_since_restore': 198.47502732276917,\n",
            " 'time_this_iter_s': 67.63544034957886,\n",
            " 'time_total_s': 1983.5876326560974,\n",
            " 'timers': {'learn_throughput': 67.071,\n",
            "            'learn_time_ms': 59638.116,\n",
            "            'load_throughput': 84035.383,\n",
            "            'load_time_ms': 47.599,\n",
            "            'synch_weights_time_ms': 5.721,\n",
            "            'training_iteration_time_ms': 66152.612},\n",
            " 'timestamp': 1701165342,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 120000,\n",
            " 'training_iteration': 30,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.575826644897461}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 1 Environment LabyrinthExploreMedium:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=823071)\u001b[0m 2023-11-28 02:55:46,212\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=823071)\u001b[0m 2023-11-28 02:55:46,212\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:55:47,115\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:55:47,145\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_1_env_LabyrinthExploreEasy/checkpoint_000030\n",
            "2023-11-28 02:55:47,145\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 30, '_timesteps_total': None, '_time_total': 1983.5876326560974, '_episodes_total': 108}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 124000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd565daaf0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c226f10>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030100345611572266,\n",
            "                       'StateBufferConnector_ms': 0.005435943603515625,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12445449829101562},\n",
            " 'counters': {'num_agent_steps_sampled': 124000,\n",
            "              'num_agent_steps_trained': 124000,\n",
            "              'num_env_steps_sampled': 124000,\n",
            "              'num_env_steps_trained': 124000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-56-54',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.671734052835052,\n",
            " 'episode_reward_mean': -0.7845924613402064,\n",
            " 'episode_reward_min': -0.8974508698453608,\n",
            " 'episodes_this_iter': 2,\n",
            " 'episodes_total': 110,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                'episode_reward': [-0.671734052835052, -0.8974508698453608]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.4500000000000001,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.8621960527153425,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.01513007869915029,\n",
            "                                                           'policy_loss': -0.03514084148230732,\n",
            "                                                           'total_loss': -0.02593404978754059,\n",
            "                                                           'vf_explained_var': -0.98800586532521,\n",
            "                                                           'vf_loss': 0.0023982582637609574},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 124000,\n",
            "          'num_agent_steps_trained': 124000,\n",
            "          'num_env_steps_sampled': 124000,\n",
            "          'num_env_steps_trained': 124000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 124000,\n",
            " 'num_agent_steps_trained': 124000,\n",
            " 'num_env_steps_sampled': 124000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 124000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.2494845360824742,\n",
            "          'ram_util_percent': 5.10618556701031},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09624324161847908,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.1404641092806563,\n",
            "                  'mean_inference_ms': 2.6458374921349748,\n",
            "                  'mean_raw_obs_processing_ms': 0.2868984533154565},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.030100345611572266,\n",
            "                                           'StateBufferConnector_ms': 0.005435943603515625,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12445449829101562},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.671734052835052,\n",
            "                     'episode_reward_mean': -0.7845924613402064,\n",
            "                     'episode_reward_min': -0.8974508698453608,\n",
            "                     'episodes_this_iter': 2,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                                    'episode_reward': [-0.671734052835052,\n",
            "                                                       -0.8974508698453608]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09624324161847908,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.1404641092806563,\n",
            "                                      'mean_inference_ms': 2.6458374921349748,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2868984533154565}},\n",
            " 'time_since_restore': 67.66981554031372,\n",
            " 'time_this_iter_s': 67.66981554031372,\n",
            " 'time_total_s': 2051.257448196411,\n",
            " 'timers': {'learn_throughput': 65.355,\n",
            "            'learn_time_ms': 61204.167,\n",
            "            'load_throughput': 69083.548,\n",
            "            'load_time_ms': 57.901,\n",
            "            'synch_weights_time_ms': 5.493,\n",
            "            'training_iteration_time_ms': 67661.437},\n",
            " 'timestamp': 1701165414,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 124000,\n",
            " 'training_iteration': 31,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.651261568069458}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 128000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd565daaf0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd151cd310>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.031153361002604168,\n",
            "                       'StateBufferConnector_ms': 0.005288918813069661,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.1223603884379069},\n",
            " 'counters': {'num_agent_steps_sampled': 128000,\n",
            "              'num_agent_steps_trained': 128000,\n",
            "              'num_env_steps_sampled': 128000,\n",
            "              'num_env_steps_trained': 128000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-58-00',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.5927331668814432,\n",
            " 'episode_reward_mean': -0.7639017531142613,\n",
            " 'episode_reward_min': -0.8974508698453608,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 114,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.671734052835052,\n",
            "                                   -0.8974508698453608,\n",
            "                                   -0.5927331668814432,\n",
            "                                   -0.6943057345360826,\n",
            "                                   -0.8297358247422681,\n",
            "                                   -0.8974508698453608]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.4500000000000001,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.8676287457678054,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.018588793308473316,\n",
            "                                                           'policy_loss': -0.04186574064609077,\n",
            "                                                           'total_loss': -0.03175214747380879,\n",
            "                                                           'vf_explained_var': -0.9547940670616097,\n",
            "                                                           'vf_loss': 0.0017486352020124388},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 128000,\n",
            "          'num_agent_steps_trained': 128000,\n",
            "          'num_env_steps_sampled': 128000,\n",
            "          'num_env_steps_trained': 128000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 128000,\n",
            " 'num_agent_steps_trained': 128000,\n",
            " 'num_env_steps_sampled': 128000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 128000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.1276595744680855,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09583374776387142,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.13999828228867847,\n",
            "                  'mean_inference_ms': 2.6455010860336206,\n",
            "                  'mean_raw_obs_processing_ms': 0.28763132137188113},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.031153361002604168,\n",
            "                                           'StateBufferConnector_ms': 0.005288918813069661,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.1223603884379069},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.5927331668814432,\n",
            "                     'episode_reward_mean': -0.7639017531142613,\n",
            "                     'episode_reward_min': -0.8974508698453608,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.671734052835052,\n",
            "                                                       -0.8974508698453608,\n",
            "                                                       -0.5927331668814432,\n",
            "                                                       -0.6943057345360826,\n",
            "                                                       -0.8297358247422681,\n",
            "                                                       -0.8974508698453608]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09583374776387142,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.13999828228867847,\n",
            "                                      'mean_inference_ms': 2.6455010860336206,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28763132137188113}},\n",
            " 'time_since_restore': 133.7675392627716,\n",
            " 'time_this_iter_s': 66.09772372245789,\n",
            " 'time_total_s': 2117.355171918869,\n",
            " 'timers': {'learn_throughput': 66.202,\n",
            "            'learn_time_ms': 60421.209,\n",
            "            'load_throughput': 64733.032,\n",
            "            'load_time_ms': 61.792,\n",
            "            'synch_weights_time_ms': 4.675,\n",
            "            'training_iteration_time_ms': 66875.793},\n",
            " 'timestamp': 1701165480,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 128000,\n",
            " 'training_iteration': 32,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.651261568069458}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 02:59:06,808\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='LabyrinthExploreHard', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('LabyrinthExploreHard').build()` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 132000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreMedium',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd565daaf0>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbd56292f10>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.031850337982177734,\n",
            "                       'StateBufferConnector_ms': 0.005300045013427734,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12205123901367188},\n",
            " 'counters': {'num_agent_steps_sampled': 132000,\n",
            "              'num_agent_steps_trained': 132000,\n",
            "              'num_env_steps_sampled': 132000,\n",
            "              'num_env_steps_trained': 132000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_02-59-06',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.5927331668814432,\n",
            " 'episode_reward_mean': -0.7845924613402063,\n",
            " 'episode_reward_min': -0.9425942332474226,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 118,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.671734052835052,\n",
            "                                   -0.8974508698453608,\n",
            "                                   -0.5927331668814432,\n",
            "                                   -0.6943057345360826,\n",
            "                                   -0.8297358247422681,\n",
            "                                   -0.8974508698453608,\n",
            "                                   -0.9425942332474226,\n",
            "                                   -0.9313083923969073,\n",
            "                                   -0.6717340528350523,\n",
            "                                   -0.7168774162371132]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.4500000000000001,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.791572457103319,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.025636882731064802,\n",
            "                                                           'policy_loss': -0.06064799953933044,\n",
            "                                                           'total_loss': -0.04724826385337178,\n",
            "                                                           'vf_explained_var': -0.9470929724554862,\n",
            "                                                           'vf_loss': 0.0018631395199761717},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2295.5}},\n",
            "          'num_agent_steps_sampled': 132000,\n",
            "          'num_agent_steps_trained': 132000,\n",
            "          'num_env_steps_sampled': 132000,\n",
            "          'num_env_steps_trained': 132000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 132000,\n",
            " 'num_agent_steps_trained': 132000,\n",
            " 'num_env_steps_sampled': 132000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 132000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.175531914893617,\n",
            "          'ram_util_percent': 5.100000000000002},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09566962892640643,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.1398147174204279,\n",
            "                  'mean_inference_ms': 2.6458426867590914,\n",
            "                  'mean_raw_obs_processing_ms': 0.2879887367061794},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.031850337982177734,\n",
            "                                           'StateBufferConnector_ms': 0.005300045013427734,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12205123901367188},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.5927331668814432,\n",
            "                     'episode_reward_mean': -0.7845924613402063,\n",
            "                     'episode_reward_min': -0.9425942332474226,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.671734052835052,\n",
            "                                                       -0.8974508698453608,\n",
            "                                                       -0.5927331668814432,\n",
            "                                                       -0.6943057345360826,\n",
            "                                                       -0.8297358247422681,\n",
            "                                                       -0.8974508698453608,\n",
            "                                                       -0.9425942332474226,\n",
            "                                                       -0.9313083923969073,\n",
            "                                                       -0.6717340528350523,\n",
            "                                                       -0.7168774162371132]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09566962892640643,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.1398147174204279,\n",
            "                                      'mean_inference_ms': 2.6458426867590914,\n",
            "                                      'mean_raw_obs_processing_ms': 0.2879887367061794}},\n",
            " 'time_since_restore': 199.54863333702087,\n",
            " 'time_this_iter_s': 65.78109407424927,\n",
            " 'time_total_s': 2183.1362659931183,\n",
            " 'timers': {'learn_throughput': 66.608,\n",
            "            'learn_time_ms': 60052.703,\n",
            "            'load_throughput': 64904.449,\n",
            "            'load_time_ms': 61.629,\n",
            "            'synch_weights_time_ms': 4.988,\n",
            "            'training_iteration_time_ms': 66509.001},\n",
            " 'timestamp': 1701165546,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 132000,\n",
            " 'training_iteration': 33,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.651261568069458}\n",
            "\n",
            "\n",
            "\n",
            "Starting Cycle 1 Environment LabyrinthExploreHard:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=834559)\u001b[0m 2023-11-28 02:59:10,517\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=834559)\u001b[0m 2023-11-28 02:59:10,517\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-11-28 02:59:11,349\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
            "2023-11-28 02:59:11,380\tINFO trainable.py:791 -- Restored on 129.128.243.187 from checkpoint: saved_checkpoints/agent_cycle_1_env_LabyrinthExploreMedium/checkpoint_000033\n",
            "2023-11-28 02:59:11,380\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 33, '_timesteps_total': None, '_time_total': 2183.1362659931183, '_episodes_total': 118}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent_timesteps_total': 136000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd565da700>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c8e4670>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03019571304321289,\n",
            "                       'StateBufferConnector_ms': 0.005030632019042969,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12104511260986328},\n",
            " 'counters': {'num_agent_steps_sampled': 136000,\n",
            "              'num_agent_steps_trained': 136000,\n",
            "              'num_env_steps_sampled': 136000,\n",
            "              'num_env_steps_trained': 136000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_03-00-17',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.7690156735248443,\n",
            " 'episode_reward_mean': -0.8013605153338508,\n",
            " 'episode_reward_min': -0.8337053571428572,\n",
            " 'episodes_this_iter': 2,\n",
            " 'episodes_total': 120,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                'episode_reward': [-0.7690156735248443, -0.8337053571428572]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.6750000000000002,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.8391137976800241,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.013161040558762941,\n",
            "                                                           'policy_loss': -0.036717936676997014,\n",
            "                                                           'total_loss': -0.02569101691165919,\n",
            "                                                           'vf_explained_var': -0.9683298495828464,\n",
            "                                                           'vf_loss': 0.002143218443398514},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 465.5}},\n",
            "          'num_agent_steps_sampled': 136000,\n",
            "          'num_agent_steps_trained': 136000,\n",
            "          'num_env_steps_sampled': 136000,\n",
            "          'num_env_steps_trained': 136000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 136000,\n",
            " 'num_agent_steps_trained': 136000,\n",
            " 'num_env_steps_sampled': 136000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 136000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.3563829787234036,\n",
            "          'ram_util_percent': 5.106382978723406},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09358513063338325,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.14060542084228272,\n",
            "                  'mean_inference_ms': 2.6731974836708847,\n",
            "                  'mean_raw_obs_processing_ms': 0.28275246026812645},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03019571304321289,\n",
            "                                           'StateBufferConnector_ms': 0.005030632019042969,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12104511260986328},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.7690156735248443,\n",
            "                     'episode_reward_mean': -0.8013605153338508,\n",
            "                     'episode_reward_min': -0.8337053571428572,\n",
            "                     'episodes_this_iter': 2,\n",
            "                     'hist_stats': {'episode_lengths': [1023, 1023],\n",
            "                                    'episode_reward': [-0.7690156735248443,\n",
            "                                                       -0.8337053571428572]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09358513063338325,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.14060542084228272,\n",
            "                                      'mean_inference_ms': 2.6731974836708847,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28275246026812645}},\n",
            " 'time_since_restore': 65.79162168502808,\n",
            " 'time_this_iter_s': 65.79162168502808,\n",
            " 'time_total_s': 2248.9278876781464,\n",
            " 'timers': {'learn_throughput': 67.471,\n",
            "            'learn_time_ms': 59284.77,\n",
            "            'load_throughput': 70787.253,\n",
            "            'load_time_ms': 56.507,\n",
            "            'synch_weights_time_ms': 5.559,\n",
            "            'training_iteration_time_ms': 65784.765},\n",
            " 'timestamp': 1701165617,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 136000,\n",
            " 'training_iteration': 34,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.566760540008545}\n",
            "Saving weights: Timesteps  4000\n",
            "{'agent_timesteps_total': 140000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd565da700>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c865490>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03103017807006836,\n",
            "                       'StateBufferConnector_ms': 0.004927317301432292,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12140671412150066},\n",
            " 'counters': {'num_agent_steps_sampled': 140000,\n",
            "              'num_agent_steps_trained': 140000,\n",
            "              'num_env_steps_sampled': 140000,\n",
            "              'num_env_steps_trained': 140000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_03-01-18',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.5965098505434778,\n",
            " 'episode_reward_mean': -0.7678177164208072,\n",
            " 'episode_reward_min': -0.8337053571428572,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 124,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023, 1023, 1023, 1023, 1023, 1023],\n",
            "                'episode_reward': [-0.7690156735248443,\n",
            "                                   -0.8337053571428572,\n",
            "                                   -0.7762034161490682,\n",
            "                                   -0.8049543866459624,\n",
            "                                   -0.5965098505434778,\n",
            "                                   -0.8265176145186335]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 449.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.675,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.8789318123128679,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.011083062267352943,\n",
            "                                                           'policy_loss': -0.056014536312884756,\n",
            "                                                           'total_loss': -0.047093131293853126,\n",
            "                                                           'vf_explained_var': -0.989240830540657,\n",
            "                                                           'vf_loss': 0.0014403381796566667},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 1380.5}},\n",
            "          'num_agent_steps_sampled': 140000,\n",
            "          'num_agent_steps_trained': 140000,\n",
            "          'num_env_steps_sampled': 140000,\n",
            "          'num_env_steps_trained': 140000},\n",
            " 'iterations_since_restore': 2,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 140000,\n",
            " 'num_agent_steps_trained': 140000,\n",
            " 'num_env_steps_sampled': 140000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 140000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.272727272727273,\n",
            "          'ram_util_percent': 5.1000000000000005},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09337460102884894,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.14009502440208693,\n",
            "                  'mean_inference_ms': 2.6759562189476207,\n",
            "                  'mean_raw_obs_processing_ms': 0.28459026567053597},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03103017807006836,\n",
            "                                           'StateBufferConnector_ms': 0.004927317301432292,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12140671412150066},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.5965098505434778,\n",
            "                     'episode_reward_mean': -0.7678177164208072,\n",
            "                     'episode_reward_min': -0.8337053571428572,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.7690156735248443,\n",
            "                                                       -0.8337053571428572,\n",
            "                                                       -0.7762034161490682,\n",
            "                                                       -0.8049543866459624,\n",
            "                                                       -0.5965098505434778,\n",
            "                                                       -0.8265176145186335]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09337460102884894,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.14009502440208693,\n",
            "                                      'mean_inference_ms': 2.6759562189476207,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28459026567053597}},\n",
            " 'time_since_restore': 127.34707379341125,\n",
            " 'time_this_iter_s': 61.55545210838318,\n",
            " 'time_total_s': 2310.4833397865295,\n",
            " 'timers': {'learn_throughput': 69.957,\n",
            "            'learn_time_ms': 57178.067,\n",
            "            'load_throughput': 87826.642,\n",
            "            'load_time_ms': 45.544,\n",
            "            'synch_weights_time_ms': 5.538,\n",
            "            'training_iteration_time_ms': 63667.382},\n",
            " 'timestamp': 1701165678,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 140000,\n",
            " 'training_iteration': 35,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.566760540008545}\n",
            "Saving weights: Timesteps  8000\n",
            "{'agent_timesteps_total': 144000,\n",
            " 'config': {'_disable_action_flattening': False,\n",
            "            '_disable_execution_plan_api': True,\n",
            "            '_disable_preprocessor_api': False,\n",
            "            '_enable_rl_module_api': False,\n",
            "            '_enable_rl_trainer_api': False,\n",
            "            '_fake_gpus': False,\n",
            "            '_rl_trainer_hps': RLTrainerHPs(),\n",
            "            '_tf_policy_handles_more_than_one_loss': False,\n",
            "            'action_space': None,\n",
            "            'actions_in_input_normalized': False,\n",
            "            'always_attach_evaluation_results': False,\n",
            "            'auto_wrap_old_gym_envs': True,\n",
            "            'batch_mode': 'truncate_episodes',\n",
            "            'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
            "            'checkpoint_trainable_policies_only': False,\n",
            "            'clip_actions': False,\n",
            "            'clip_param': 0.3,\n",
            "            'clip_rewards': None,\n",
            "            'compress_observations': False,\n",
            "            'create_env_on_driver': False,\n",
            "            'custom_eval_function': None,\n",
            "            'custom_resources_per_worker': {},\n",
            "            'disable_env_checking': False,\n",
            "            'eager_max_retraces': 20,\n",
            "            'eager_tracing': False,\n",
            "            'enable_async_evaluation': False,\n",
            "            'enable_connectors': True,\n",
            "            'enable_tf1_exec_eagerly': False,\n",
            "            'entropy_coeff': 0.0,\n",
            "            'entropy_coeff_schedule': None,\n",
            "            'env': 'LabyrinthExploreHard',\n",
            "            'env_config': {},\n",
            "            'env_task_fn': None,\n",
            "            'evaluation_config': None,\n",
            "            'evaluation_duration': 10,\n",
            "            'evaluation_duration_unit': 'episodes',\n",
            "            'evaluation_interval': None,\n",
            "            'evaluation_num_workers': 0,\n",
            "            'evaluation_parallel_to_training': False,\n",
            "            'evaluation_sample_timeout_s': 180.0,\n",
            "            'exploration_config': {'type': 'StochasticSampling'},\n",
            "            'explore': True,\n",
            "            'export_native_model_files': False,\n",
            "            'extra_python_environs_for_driver': {},\n",
            "            'extra_python_environs_for_worker': {},\n",
            "            'fake_sampler': False,\n",
            "            'framework': 'torch',\n",
            "            'gamma': 0.99,\n",
            "            'grad_clip': None,\n",
            "            'horizon': -1,\n",
            "            'ignore_worker_failures': False,\n",
            "            'in_evaluation': False,\n",
            "            'input': 'sampler',\n",
            "            'input_config': {},\n",
            "            'is_atari': False,\n",
            "            'keep_per_episode_custom_metrics': False,\n",
            "            'kl_coeff': 0.2,\n",
            "            'kl_target': 0.01,\n",
            "            'lambda': 1.0,\n",
            "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                                      'intra_op_parallelism_threads': 8},\n",
            "            'log_level': 'WARN',\n",
            "            'log_sys_usage': True,\n",
            "            'logger_config': None,\n",
            "            'logger_creator': None,\n",
            "            'lr': 5e-05,\n",
            "            'lr_schedule': None,\n",
            "            'max_requests_in_flight_per_sampler_worker': 2,\n",
            "            'metrics_episode_collection_timeout_s': 60.0,\n",
            "            'metrics_num_episodes_for_smoothing': 100,\n",
            "            'min_sample_timesteps_per_iteration': 0,\n",
            "            'min_time_s_per_iteration': None,\n",
            "            'min_train_timesteps_per_iteration': 0,\n",
            "            'model': {'_disable_action_flattening': False,\n",
            "                      '_disable_preprocessor_api': False,\n",
            "                      '_time_major': False,\n",
            "                      '_use_default_native_models': -1,\n",
            "                      'attention_dim': 64,\n",
            "                      'attention_head_dim': 32,\n",
            "                      'attention_init_gru_gate_bias': 2.0,\n",
            "                      'attention_memory_inference': 50,\n",
            "                      'attention_memory_training': 50,\n",
            "                      'attention_num_heads': 1,\n",
            "                      'attention_num_transformer_units': 1,\n",
            "                      'attention_position_wise_mlp_dim': 32,\n",
            "                      'attention_use_n_prev_actions': 0,\n",
            "                      'attention_use_n_prev_rewards': 0,\n",
            "                      'conv_activation': 'relu',\n",
            "                      'conv_filters': None,\n",
            "                      'custom_action_dist': None,\n",
            "                      'custom_model': None,\n",
            "                      'custom_model_config': {},\n",
            "                      'custom_preprocessor': None,\n",
            "                      'dim': 84,\n",
            "                      'fcnet_activation': 'tanh',\n",
            "                      'fcnet_hiddens': [256, 256],\n",
            "                      'framestack': True,\n",
            "                      'free_log_std': False,\n",
            "                      'grayscale': False,\n",
            "                      'lstm_cell_size': 256,\n",
            "                      'lstm_use_prev_action': False,\n",
            "                      'lstm_use_prev_action_reward': -1,\n",
            "                      'lstm_use_prev_reward': False,\n",
            "                      'max_seq_len': 20,\n",
            "                      'no_final_linear': False,\n",
            "                      'post_fcnet_activation': 'relu',\n",
            "                      'post_fcnet_hiddens': [],\n",
            "                      'use_attention': True,\n",
            "                      'use_lstm': False,\n",
            "                      'vf_share_layers': False,\n",
            "                      'zero_mean': True},\n",
            "            'multiagent': {'count_steps_by': 'env_steps',\n",
            "                           'observation_fn': None,\n",
            "                           'policies': {'default_policy': (None,\n",
            "                                                           None,\n",
            "                                                           None,\n",
            "                                                           None)},\n",
            "                           'policies_to_train': None,\n",
            "                           'policy_map_cache': -1,\n",
            "                           'policy_map_capacity': 100,\n",
            "                           'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fbd565da700>},\n",
            "            'no_done_at_end': -1,\n",
            "            'normalize_actions': True,\n",
            "            'num_consecutive_worker_failures_tolerance': 100,\n",
            "            'num_cpus': 11,\n",
            "            'num_cpus_for_driver': 3,\n",
            "            'num_cpus_per_trainer_worker': 1,\n",
            "            'num_cpus_per_worker': 2,\n",
            "            'num_envs_per_worker': 1,\n",
            "            'num_gpus': 4,\n",
            "            'num_gpus_per_trainer_worker': 0,\n",
            "            'num_gpus_per_worker': 1,\n",
            "            'num_sgd_iter': 30,\n",
            "            'num_trainer_workers': 0,\n",
            "            'num_workers': 2,\n",
            "            'observation_filter': 'NoFilter',\n",
            "            'observation_space': None,\n",
            "            'off_policy_estimation_methods': {},\n",
            "            'offline_sampling': False,\n",
            "            'ope_split_batch_by_episode': True,\n",
            "            'optimizer': {},\n",
            "            'output': None,\n",
            "            'output_compress_columns': ['obs', 'new_obs'],\n",
            "            'output_config': {},\n",
            "            'output_max_file_size': 67108864,\n",
            "            'placement_strategy': 'PACK',\n",
            "            'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7fbe7c250f10>},\n",
            "            'policy_states_are_swappable': False,\n",
            "            'postprocess_inputs': False,\n",
            "            'preprocessor_pref': 'deepmind',\n",
            "            'recreate_failed_workers': False,\n",
            "            'remote_env_batch_wait_ms': 0,\n",
            "            'remote_worker_envs': False,\n",
            "            'render_env': False,\n",
            "            'replay_sequence_length': None,\n",
            "            'restart_failed_sub_environments': False,\n",
            "            'rl_module_class': None,\n",
            "            'rl_trainer_class': None,\n",
            "            'rollout_fragment_length': 'auto',\n",
            "            'sample_async': False,\n",
            "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            "            'sampler_perf_stats_ema_coef': None,\n",
            "            'seed': None,\n",
            "            'sgd_minibatch_size': 128,\n",
            "            'shuffle_buffer_size': 0,\n",
            "            'shuffle_sequences': True,\n",
            "            'simple_optimizer': False,\n",
            "            'soft_horizon': -1,\n",
            "            'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
            "            'synchronize_filters': True,\n",
            "            'tf_session_args': {'allow_soft_placement': True,\n",
            "                                'device_count': {'CPU': 1},\n",
            "                                'gpu_options': {'allow_growth': True},\n",
            "                                'inter_op_parallelism_threads': 2,\n",
            "                                'intra_op_parallelism_threads': 2,\n",
            "                                'log_device_placement': False},\n",
            "            'train_batch_size': 4000,\n",
            "            'use_critic': True,\n",
            "            'use_gae': True,\n",
            "            'validate_workers_after_construction': True,\n",
            "            'vf_clip_param': 10.0,\n",
            "            'vf_loss_coeff': 1.0,\n",
            "            'vf_share_layers': -1,\n",
            "            'worker_cls': None,\n",
            "            'worker_health_probe_timeout_s': 60,\n",
            "            'worker_restore_timeout_s': 1800},\n",
            " 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.031561851501464844,\n",
            "                       'StateBufferConnector_ms': 0.004944801330566406,\n",
            "                       'ViewRequirementAgentConnector_ms': 0.12133359909057617},\n",
            " 'counters': {'num_agent_steps_sampled': 144000,\n",
            "              'num_agent_steps_trained': 144000,\n",
            "              'num_env_steps_sampled': 144000,\n",
            "              'num_env_steps_trained': 144000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2023-11-28_03-02-24',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 1023.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': -0.5965098505434778,\n",
            " 'episode_reward_mean': -0.8121421292701863,\n",
            " 'episode_reward_min': -0.9702724670031055,\n",
            " 'episodes_this_iter': 4,\n",
            " 'episodes_total': 128,\n",
            " 'experiment_id': 'facf5e8f2c5f405d8c6eb74c64d40117',\n",
            " 'hist_stats': {'episode_lengths': [1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023,\n",
            "                                    1023],\n",
            "                'episode_reward': [-0.7690156735248443,\n",
            "                                   -0.8337053571428572,\n",
            "                                   -0.7762034161490682,\n",
            "                                   -0.8049543866459624,\n",
            "                                   -0.5965098505434778,\n",
            "                                   -0.8265176145186335,\n",
            "                                   -0.7546401882763973,\n",
            "                                   -0.9127705260093169,\n",
            "                                   -0.9702724670031055,\n",
            "                                   -0.8768318128881988]},\n",
            " 'hostname': 'karma',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'diff_num_grad_updates_vs_sampler_policy': 464.5,\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.6750000000000002,\n",
            "                                                           'cur_lr': 5.0000000000000016e-05,\n",
            "                                                           'entropy': 0.7299449666853874,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.017223625338134988,\n",
            "                                                           'policy_loss': -0.020212852678471997,\n",
            "                                                           'total_loss': -0.007536662530194047,\n",
            "                                                           'vf_explained_var': -0.9500561106589532,\n",
            "                                                           'vf_loss': 0.0010502429116831503},\n",
            "                                         'model': {},\n",
            "                                         'num_grad_updates_lifetime': 2295.5}},\n",
            "          'num_agent_steps_sampled': 144000,\n",
            "          'num_agent_steps_trained': 144000,\n",
            "          'num_env_steps_sampled': 144000,\n",
            "          'num_env_steps_trained': 144000},\n",
            " 'iterations_since_restore': 3,\n",
            " 'node_ip': '129.128.243.187',\n",
            " 'num_agent_steps_sampled': 144000,\n",
            " 'num_agent_steps_trained': 144000,\n",
            " 'num_env_steps_sampled': 144000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 144000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_faulty_episodes': 0,\n",
            " 'num_healthy_workers': 2,\n",
            " 'num_in_flight_async_reqs': 0,\n",
            " 'num_remote_worker_restarts': 0,\n",
            " 'num_steps_trained_this_iter': 4000,\n",
            " 'perf': {'cpu_util_percent': 3.7617021276595755,\n",
            "          'ram_util_percent': 5.339361702127657},\n",
            " 'pid': 699633,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.09328641011920716,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.13983052990233985,\n",
            "                  'mean_inference_ms': 2.6772084705341563,\n",
            "                  'mean_raw_obs_processing_ms': 0.28529853379166487},\n",
            " 'sampler_results': {'connector_metrics': {'ObsPreprocessorConnector_ms': 0.031561851501464844,\n",
            "                                           'StateBufferConnector_ms': 0.004944801330566406,\n",
            "                                           'ViewRequirementAgentConnector_ms': 0.12133359909057617},\n",
            "                     'custom_metrics': {},\n",
            "                     'episode_len_mean': 1023.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': -0.5965098505434778,\n",
            "                     'episode_reward_mean': -0.8121421292701863,\n",
            "                     'episode_reward_min': -0.9702724670031055,\n",
            "                     'episodes_this_iter': 4,\n",
            "                     'hist_stats': {'episode_lengths': [1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023,\n",
            "                                                        1023],\n",
            "                                    'episode_reward': [-0.7690156735248443,\n",
            "                                                       -0.8337053571428572,\n",
            "                                                       -0.7762034161490682,\n",
            "                                                       -0.8049543866459624,\n",
            "                                                       -0.5965098505434778,\n",
            "                                                       -0.8265176145186335,\n",
            "                                                       -0.7546401882763973,\n",
            "                                                       -0.9127705260093169,\n",
            "                                                       -0.9702724670031055,\n",
            "                                                       -0.8768318128881988]},\n",
            "                     'num_faulty_episodes': 0,\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.09328641011920716,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.13983052990233985,\n",
            "                                      'mean_inference_ms': 2.6772084705341563,\n",
            "                                      'mean_raw_obs_processing_ms': 0.28529853379166487}},\n",
            " 'time_since_restore': 193.21418356895447,\n",
            " 'time_this_iter_s': 65.86710977554321,\n",
            " 'time_total_s': 2376.3504495620728,\n",
            " 'timers': {'learn_throughput': 69.09,\n",
            "            'learn_time_ms': 57895.487,\n",
            "            'load_throughput': 82475.61,\n",
            "            'load_time_ms': 48.499,\n",
            "            'synch_weights_time_ms': 5.641,\n",
            "            'training_iteration_time_ms': 64399.041},\n",
            " 'timestamp': 1701165744,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 144000,\n",
            " 'training_iteration': 36,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 4.566760540008545}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total_timesteps = 0\n",
        "prev_env_timesteps = 0\n",
        "for cycle_count in range(num_of_cycles):\n",
        "    for env in envs:\n",
        "        print(f'Starting Cycle {cycle_count} Environment {env}:')\n",
        "        config = {\n",
        "            \"env\": env,\n",
        "            \"num_cpus\": 11,  # https://discuss.ray.io/t/total-workers-number-of-gpus-1/9292/2\n",
        "            \"num_gpus\": 4,\n",
        "            \"num_gpus_per_worker\": 1,\n",
        "            \"num_cpus_per_worker\": 2,\n",
        "            \"num_cpus_for_local_worker\": 3,\n",
        "            \"model\": model,\n",
        "            \"framework\": \"torch\"\n",
        "        }\n",
        "\n",
        "        trainer = PPOTrainer(env=env, config=config)\n",
        "        if previous_checkpoint_path is not None:\n",
        "            trainer.restore(previous_checkpoint_path+'/'+sorted(os.listdir(previous_checkpoint_path))[-1])\n",
        "\n",
        "        previous_checkpoint_path = f\"saved_checkpoints/agent_cycle_{cycle_count}_env_{env}\"\n",
        "        curr_env_timesteps = 0\n",
        "        #variables to check whether algorithm has reached weight save points\n",
        "        start_checkpoint = False\n",
        "        midway_checkpoint = False\n",
        "        while curr_env_timesteps < total_timesteps_per_cycle:\n",
        "            result = trainer.train()\n",
        "\n",
        "            mean_reward_per_episode[env].append(result['episode_reward_mean'])\n",
        "            pprint.pprint(result)\n",
        "            total_timesteps = result['timesteps_total']\n",
        "            curr_env_timesteps = total_timesteps - prev_env_timesteps\n",
        "            timesteps_done[env].append(curr_env_timesteps)\n",
        "\n",
        "            # save weights when training checkpoints are reached\n",
        "            # 1 represents start checkpoint and 2 is midway checkpoint\n",
        "            if not start_checkpoint and curr_env_timesteps > 0:\n",
        "                print('Saving weights: Timesteps ', curr_env_timesteps)\n",
        "                with open(f'saved_weights/weights_cycle_{cycle_count}_env_{env}_stage_1.pkl', 'wb') as f:\n",
        "                    weights = trainer.get_weights()\n",
        "                    pickle.dump(weights, f)\n",
        "                start_checkpoint = True\n",
        "\n",
        "            if not midway_checkpoint and curr_env_timesteps >= total_timesteps_per_cycle / 2:\n",
        "                print('Saving weights: Timesteps ', curr_env_timesteps)\n",
        "                with open(f'saved_weights/weights_cycle_{cycle_count}_env_{env}_stage_2.pkl', 'wb') as f:\n",
        "                    weights = trainer.get_weights()\n",
        "                    pickle.dump(weights, f)\n",
        "                midway_checkpoint = True\n",
        "\n",
        "        trainer.save(previous_checkpoint_path)\n",
        "\n",
        "        prev_env_timesteps = total_timesteps\n",
        "\n",
        "        print('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JBy1nMDo4qHu"
      },
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93k-vpnK7jdx",
        "outputId": "50316da8-c177-418f-8801-b41658b843f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'LabyrinthEscapeEasy': [-0.6214192708333334,\n",
              "  -0.50634765625,\n",
              "  -0.4560546875,\n",
              "  -0.12451171875,\n",
              "  -0.4080810546875,\n",
              "  -0.6050618489583334],\n",
              " 'LabyrinthEscapeMedium': [-0.9990234375,\n",
              "  -0.9990234375,\n",
              "  -0.8718927556818182,\n",
              "  -0.4248046875,\n",
              "  -0.6708984375,\n",
              "  -0.7902166193181818],\n",
              " 'LabyrinthEscapeHard': [-0.572265625,\n",
              "  -0.8161272321428571,\n",
              "  -0.8826349431818182,\n",
              "  -0.9990234375,\n",
              "  -0.9990234375,\n",
              "  -0.9990234375],\n",
              " 'LabyrinthExploreEasy': [-0.6034060108418366,\n",
              "  -0.4679694143282312,\n",
              "  -0.4750976562499999,\n",
              "  -0.4750976562500001,\n",
              "  -0.5570724383503401,\n",
              "  -0.6376215720663265],\n",
              " 'LabyrinthExploreMedium': [-0.6378765302835052,\n",
              "  -0.6754959997852233,\n",
              "  -0.6570624597293815,\n",
              "  -0.7845924613402064,\n",
              "  -0.7639017531142613,\n",
              "  -0.7845924613402063],\n",
              " 'LabyrinthExploreHard': [-0.7905789013975154,\n",
              "  -0.784589115877329,\n",
              "  -0.8071107094332298,\n",
              "  -0.8013605153338508,\n",
              "  -0.7678177164208072,\n",
              "  -0.8121421292701863]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_reward_per_episode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K_66WisROYIW"
      },
      "outputs": [],
      "source": [
        "with open('mean_reward_per_episode.json', 'w') as f:\n",
        "    json.dump(mean_reward_per_episode, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8RDjLUF7kkR",
        "outputId": "e4f0f774-da83-4908-cc27-385b5179e4a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'LabyrinthEscapeEasy': [4000, 8000, 12000, 4000, 8000, 12000],\n",
              " 'LabyrinthEscapeMedium': [4000, 8000, 12000, 4000, 8000, 12000],\n",
              " 'LabyrinthEscapeHard': [4000, 8000, 12000, 4000, 8000, 12000],\n",
              " 'LabyrinthExploreEasy': [4000, 8000, 12000, 4000, 8000, 12000],\n",
              " 'LabyrinthExploreMedium': [4000, 8000, 12000, 4000, 8000, 12000],\n",
              " 'LabyrinthExploreHard': [4000, 8000, 12000, 4000, 8000, 12000]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timesteps_done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X26L62ILEJje",
        "outputId": "678951d9-e28b-467a-ccec-3ad983938fc1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for env in envs:\n",
        "    plt.plot(mean_reward_per_episode[env])\n",
        "    plt.title(env)\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Average Reward per Episode')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
